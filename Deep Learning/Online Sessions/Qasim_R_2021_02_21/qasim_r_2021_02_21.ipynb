{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning - Muhammad Qasim - 2021/02/21"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpBkTS_KMfVP"
      },
      "source": [
        "# Chapter 02 - Before we begin: the mathematical building blocks of neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YnOJ5SDaikh"
      },
      "source": [
        "- Tensor\n",
        "  - Multidimesnion numpy arrays are known as tensors\n",
        "  - container of data\n",
        "- Tensor Operations\n",
        "  - Layers building blocks\n",
        "  - gears of neural networks\n",
        "- differentiation\n",
        "  - process of finding rate of change\n",
        "- gradient descent\n",
        "  - algorithm to minimize a function by moving in direction of steepest descent\n",
        "  - allows your model to learn from its training examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLqmf_ZuMfVb"
      },
      "source": [
        "## 2.1 A first look at a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb_3OLQAbJS4"
      },
      "source": [
        "- A category in a classification problem is called a class. \n",
        "- Data points are called samples. \n",
        "- The class associated with a specific sample is called a label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gp87GnocMfVe"
      },
      "outputs": [],
      "source": [
        "# Listing 2.1 Loading the MNIST dataset in Keras\n",
        "\n",
        "    # grayscale images\n",
        "    # 28 * 28 pixcels\n",
        "    # 10 classes\n",
        "    # 60000 training\n",
        "    # 10000 testing\n",
        "\n",
        "# import mnist data set from keras\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aFSjlLrgMfVf"
      },
      "outputs": [],
      "source": [
        "# Listing 2.1 Loading the MNIST dataset in Keras\n",
        "\n",
        "# split data to training and testing data sets\n",
        "# data\n",
        "    # images\n",
        "    # labels\n",
        "# train_images and train_labels form the training set,\n",
        "# test set, test_images and test_labels\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# The images are encoded as Numpy arrays\n",
        "# labels are an array of digits, ranging from 0 to 9. \n",
        "# The images and labels have a one-to-one correspondence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rakMNB1eMfVh",
        "outputId": "1cab7879-5a93-4a8e-bd09-60a1b101f379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training images :  (60000, 28, 28)\n",
            "Shape of training images labels :  (60000,)\n",
            "Labels of training images :  [5 0 4 ... 5 6 8]\n"
          ]
        }
      ],
      "source": [
        "# training data\n",
        "print(\"Shape of training images : \",train_images.shape)\n",
        "print(\"Shape of training images labels : \",train_labels.shape)\n",
        "print(\"Labels of training images : \",train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMUNneR2MfVi",
        "outputId": "792d1d98-1943-479e-c4b4-4a96338dac08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of test images :  (10000, 28, 28)\n",
            "Shape of test images labels :  (10000,)\n",
            "Labels of test images :  [7 2 1 ... 4 5 6]\n"
          ]
        }
      ],
      "source": [
        "# testing data\n",
        "print(\"Shape of test images : \",test_images.shape)\n",
        "print(\"Shape of test images labels : \",test_labels.shape)\n",
        "print(\"Labels of test images : \",test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "906JC8v7bR_M"
      },
      "source": [
        "- WorkFlow\n",
        "  - feed the neural network the training data\n",
        "  - learn to associate images and labels\n",
        "  - ask the network to produce predictions for test_images\n",
        "  - verify whether these predictions match the labels from test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "yAEPkwASMfVl",
        "outputId": "5f1992b6-dbf3-4977-f391-67a1f1741b12"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check one of the image\n",
        "import matplotlib.pylab as plt\n",
        "def plti(im, h=8, **kwargs):\n",
        "    \"\"\"\n",
        "    Helper function to plot an image.\n",
        "    \"\"\"\n",
        "    y = im.shape[0]\n",
        "    x = im.shape[1]\n",
        "    w = (y/x) * h\n",
        "    plt.figure(figsize=(w, h))\n",
        "    plt.imshow(im, interpolation=\"none\", **kwargs)\n",
        "    plt.axis('off')\n",
        "plti(train_images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXDBuLZMbfVJ"
      },
      "source": [
        "- Layer\n",
        "  - The core building block of neural networks \n",
        "  - a data-processing module (filter).\n",
        "  - Some data goes in, and it comes out in a more use-ful form.\n",
        "  - Extract representations\n",
        "- Deep learning consists of channing together simple layers whihc forms data distillation\n",
        "- Model\n",
        "  - made of refined data filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "70ri_cdfMfVn"
      },
      "outputs": [],
      "source": [
        "# Listing 2.2 The network architecture\n",
        "\n",
        "# import model and layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define network and layers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512,activation=\"relu\"),\n",
        "    layers.Dense(10,activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDR8_wmAb1Eu"
      },
      "source": [
        "- sequential model process one layer at a time\n",
        "- Dense is type of neural network\n",
        "- input shape defines shape of input data if added to layer\n",
        "- initial number is shape of output data from a layer / nodes of layer\n",
        "- activation function \n",
        "  - transform linearity to non-linearity \n",
        "  - defines how weighted sum is transformed\n",
        "- relu is rectified linear unit it returns as it is if positive other wise zero\n",
        "- softmax predict a multinomial probability distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWFSBll_b9Sk"
      },
      "source": [
        "- Compilation step\n",
        "  - An optimizer\n",
        "    - The mechanism through which the model will update itself based on the training data it sees, \n",
        "    - so as to improve its performance.\n",
        "  - A loss function\n",
        "    - How the model will be able to measure its performance on the training data, \n",
        "    - and thus how it will be able to steer itself in the right direction.\n",
        "  - Metrics to monitor during training and testing\n",
        "    - Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9bQ0LnxLMfVp"
      },
      "outputs": [],
      "source": [
        "# Listing 2.3 The compilation step\n",
        "\n",
        "model.compile(\n",
        "        optimizer=\"rmsprop\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMIDf7KQcIoV"
      },
      "source": [
        "- rmsprop\n",
        "  - Root Mean Squared Propagation\n",
        "  - The RMSprop optimizer restricts the oscillations in the vertical direction\n",
        "- sparse_categorical_crossentropy\n",
        "  - Use this crossentropy loss function when there are two or more label classes. \n",
        "  - We expect labels to be provided as integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_ObNB5fFMfVq"
      },
      "outputs": [],
      "source": [
        "# Listing 2.4 Preparing the image data\n",
        "\n",
        "# We need to reshape our data as it is of shape (60000,28,28) \n",
        "# on the other hand we need to use this data as initial nodes\n",
        "# thus data is reshaped to (60000,28*28)\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "# Initally values are between interval [0,225]\n",
        "# scale them to be in interval [0,1]\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-b-iiOncQxA"
      },
      "source": [
        "- Data\n",
        "  - Continous\n",
        "  - Discrete\n",
        "    - ordinal\n",
        "      - can be re-arranged\n",
        "    - nominal\n",
        "      - can't be re-arranged\n",
        "- One hot encoding can be used to transform data to catgorical format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AzaaLeOFMfVq"
      },
      "outputs": [],
      "source": [
        "# One hot encoding\n",
        "\n",
        "#       A*  A   B*  B   C   D   F\n",
        "#   A*  1   0   0   0   0   0   0\n",
        "#   A   0   1   0   0   0   0   0\n",
        "#   B*  0   0   1   0   0   0   0\n",
        "#   B   0   0   0   1   0   0   0\n",
        "#   C   0   0   0   0   1   0   0\n",
        "#   D   0   0   0   0   0   1   0\n",
        "#   F   0   0   0   0   0   0   1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j5t-EmNyMfVr"
      },
      "outputs": [],
      "source": [
        "# print(train_labels[0])\n",
        "# # Not as such required in latest version \n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# train_labels = to_categorical(train_labels)\n",
        "# test_labels = to_categorical(test_labels)\n",
        "# print(train_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDJsHOpzMfVr",
        "outputId": "9bcc88d7-20a6-4e3f-adfd-74b7c391d4a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 11s 20ms/step - loss: 0.2554 - accuracy: 0.9262\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.1045 - accuracy: 0.9687\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0688 - accuracy: 0.9799\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0492 - accuracy: 0.9853\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0377 - accuracy: 0.9887\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd50e385cd0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Listing 2.5 “Fitting” the model\n",
        "# train the model, \n",
        "    # we fit the model to its training data.\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "# Accuracy and loss is over the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-jYICJwMfVs",
        "outputId": "3c21578f-409c-4b1c-f024-ba0a9c36db71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([2.5061636e-08, 1.8423772e-10, 3.8960752e-06, 9.5133502e-05,\n",
              "       4.3010400e-12, 2.5220203e-07, 3.5580954e-14, 9.9989963e-01,\n",
              "       1.5831378e-07, 8.7709481e-07], dtype=float32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Listing 2.6 Using the model to make predictions\n",
        "\n",
        "import numpy as np\n",
        "# Take first 10 images from the test images\n",
        "test_digits = test_images[0:10]\n",
        "# predict the model behaviour on the slice of test images\n",
        "predictions = model.predict(test_digits)\n",
        "# check predictio of first test digit\n",
        "print(np.shape(predictions[0]))\n",
        "# Each prdiction is probability of ten classes\n",
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO5Hyx8IMfVt",
        "outputId": "fa640043-5a71-4a7f-dd1d-790c9df848c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find index of the higest probability which crosponds to the same label as index\n",
        "predictions[0].argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNfMaz5jMfVu",
        "outputId": "48862818-c04c-4663-eaf7-4d1a2b7182de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9998996"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# higest probability\n",
        "predictions[0][7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeyPGU0TMfVv",
        "outputId": "e5eab973-c8da-4add-eca8-e9bf9f2214cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the label from the test tabels\n",
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMWEsXK9MfVv",
        "outputId": "14f81ada-2226-41b9-a87d-4f5e4ad8da26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9809\n",
            "test_acc: 0.98089998960495\n",
            "test_loss: 0.06767154484987259\n"
          ]
        }
      ],
      "source": [
        "# Listing 2.7 Evaluating the model on new data\n",
        "\n",
        "# compute average accuracy over the entire test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")\n",
        "print(f\"test_loss: {test_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zChP3_djMfVw"
      },
      "outputs": [],
      "source": [
        "# gap between training accuracy and test accuracy is an example of overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9I5PDWxMfVw"
      },
      "source": [
        "## 2.2 Data representations for neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY2N-vyMcwr7"
      },
      "source": [
        "- tensors\n",
        "  - Multi-dimensional numpy array\n",
        "  - basic data structure for machine learning\n",
        "  - matrices are rank 2 tensors\n",
        "  - dimension is also termed as axis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTh6pUrvMfVx"
      },
      "source": [
        "### 2.2.1 Scalars (rank-0 tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk7HkI0mc3kz"
      },
      "source": [
        "- A tensor that contains only one number is called a scalar\n",
        "  - scalar tensor\n",
        "  - rank-0 tensor\n",
        "  - 0D tensor\n",
        "- float32 or float64 number is a scalar tensor\n",
        "- a scalar tensor has 0 axes\n",
        "- axes == rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fmS-12OMfVy",
        "outputId": "cbff3ec9-a810-4047-f3c2-3861b5f84403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X =  12\n",
            "axes =  0\n",
            "rank =  0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "print(\"X = \",x)\n",
        "print(\"axes = \",x.ndim)\n",
        "print(\"rank = \",x.ndim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i58VN3-oMfVz"
      },
      "source": [
        "### 2.2.2 Vectors (rank-1 tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zQpSjy7d942"
      },
      "source": [
        "- array of numbers is called a vector,\n",
        "    - rank-1 tensor\n",
        "    - 1D tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRwfDY8BMfVz",
        "outputId": "b4eba8a2-f402-4f94-f183-9e5c0f7ce391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X =  [12  3  6 14  7]\n",
            "axes =  1\n",
            "rank =  1\n"
          ]
        }
      ],
      "source": [
        "x = np.array([12, 3, 6, 14, 7])\n",
        "print(\"X = \",x)\n",
        "print(\"axes = \",x.ndim)\n",
        "print(\"rank = \",x.ndim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Og4o_64eDev"
      },
      "source": [
        "- a vector having five entries is 5-dimensional vector. \n",
        "- A 5D vector has only one axis and has five dimensions along its axis, \n",
        "- a 5D tensor has five axes\n",
        "- Dimensionality\n",
        "    - number of entries along a specific axis\n",
        "    - the number of axes in a tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y13uo8fVMfV0"
      },
      "source": [
        "### 2.2.3 Matrices (rank-2 tensors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix4GK1-xeIgn"
      },
      "source": [
        "- array of vectors is a matrix\n",
        "    - rank-2 tensor\n",
        "    - 2D tensor. \n",
        "- A matrix has two axes\n",
        "    - rows\n",
        "    - columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW-73LGSMfV0",
        "outputId": "c4192612-1b62-488a-c4c0-76df6005cfdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X =  [[ 5 78  2 34  0]\n",
            " [ 6 79  3 35  1]\n",
            " [ 7 80  4 36  2]]\n",
            "axes =  2\n",
            "rank =  2\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "print(\"X = \",x)\n",
        "print(\"axes = \",x.ndim)\n",
        "print(\"rank = \",x.ndim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QHyW2nOMfV1"
      },
      "source": [
        "### 2.2.4 Rank-3 and higher-rank tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47GxSxqreS17"
      },
      "source": [
        "- pack of matrices in a array\n",
        "    - rank-3 tensor\n",
        "    - 3D tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8BCYr7VMfV2",
        "outputId": "b60c22fc-96bb-4a75-a80c-5fedafe7bd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X =  [[[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]\n",
            "\n",
            " [[ 5 78  2 34  0]\n",
            "  [ 6 79  3 35  1]\n",
            "  [ 7 80  4 36  2]]]\n",
            "axes =  3\n",
            "rank =  3\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "print(\"X = \",x)\n",
        "print(\"axes = \",x.ndim)\n",
        "print(\"rank = \",x.ndim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCuj0kiieYFE"
      },
      "source": [
        "- packing rank-3 tensors in an array => rank-4 tensor\n",
        "- rank 5 if you process video data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CmtePJdMfV2"
      },
      "source": [
        "### 2.2.5 Key attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZd1E0Wdeb43"
      },
      "source": [
        "- Number of axes (rank)\n",
        "  - ndim\n",
        "- Shape\n",
        "  - dimensions the tensor has along each axis\n",
        "- Data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "O9petng7MfV3"
      },
      "outputs": [],
      "source": [
        "# Load mnist data\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28NgWNFrMfV3",
        "outputId": "fcad70e0-c615-4313-c707-369d3743a4a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimension / axes / rank of the train images\n",
        "train_images.ndim\n",
        "# it is a 3D tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQrTbN_GMfV4",
        "outputId": "e1437277-71d2-4719-f0cd-63a246a47706"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape train images\n",
        "train_images.shape\n",
        "# it has 60000 matrices of 28*28 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKaq_dRuMfV4",
        "outputId": "a2a16302-3c12-4140-bb43-0eb9a7cdfd6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data type images\n",
        "train_images.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "wlrbCK1vMfV4",
        "outputId": "90977f03-7b89-487e-9d1b-bb7c17d3ea62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Listing 2.8 Displaying the fourth image and its label\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "print(train_labels[4])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HirWEWxfMfV5"
      },
      "source": [
        "### 2.2.6 Manipulating tensors in NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p29J3iT9emAV"
      },
      "source": [
        "- tensor slicing\n",
        "    - Selecting specific elements in a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEUSaJ42MfV5",
        "outputId": "c7f7bf82-d46d-4bde-c526-c1750594407c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# select image #10 to #100\n",
        "my_slice = train_images[10:100]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxKyAmpvMfV6",
        "outputId": "9fe08a5d-513a-43ec-86eb-532ebf602f75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# a little detailed way of slicing\n",
        "# : is equivalent to selecting the entire axis\n",
        "my_slice = train_images[10:100, :, :]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWXArA-rMfV6",
        "outputId": "65f05e77-48c8-4c64-fcda-6ca74945581a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# detailed way of slicing\n",
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "A-lmUSGwMfV7",
        "outputId": "13e42ef1-e078-4204-af1d-015fabd13be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# slices between any two indices along each tensor axis.\n",
        "# 14 × 14 pixels in the bottom-right corner of all images\n",
        "my_slice = train_images[:, 14:, 14:]\n",
        "digit = my_slice[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "print(train_labels[4])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3OjKwPAPMfV7",
        "outputId": "c281eaaa-6039-48c3-fa38-433021467f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# possible to use negative indices\n",
        "# 14 × 14 pixels centered in the middle\n",
        "my_slice = train_images[:, 7:-7, 7:-7]\n",
        "digit = my_slice[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "print(train_labels[4])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQk1dcndMfV8"
      },
      "source": [
        "### 2.2.7 The notion of data batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLIAzCZuetEL"
      },
      "source": [
        "- first axis / axis 0 in all data tensors \n",
        "    - samples axis\n",
        "    - samples dimension).\n",
        "- MNIST example\n",
        "    - “samples” are images of digits.\n",
        "- deep learning models don’t process entire dataset at once; they break the data in small batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SmnSr0lMfV8",
        "outputId": "96cc61d7-d1e1-486d-bc49-38776258e506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(128, 28, 28)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# first batch of size 128\n",
        "batch = train_images[:128]\n",
        "batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twnwpwvOMfV9",
        "outputId": "29eca901-e089-4aca-9692-c0411687de1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(128, 28, 28)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# second batch of size 128\n",
        "batch = train_images[128:256]\n",
        "batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HT8J6EbMfV-",
        "outputId": "0147ec76-67d9-432c-dafd-4a68cf7128a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(128, 28, 28)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# nth batch of size 128\n",
        "n = 8\n",
        "batch = train_images[128*n:128*(n+1)]\n",
        "batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSz90D6BexqE"
      },
      "source": [
        "- in batch tensor the first axis (axis 0) is called the batch axis or batch dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bonkgHdXMfV_"
      },
      "source": [
        "### 2.2.8 Real-world examples of data tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY5dGmj6e0jo"
      },
      "source": [
        "- Vector data\n",
        "    - Rank-2 tensors\n",
        "    - shape (samples, features) , \n",
        "    - sample\n",
        "        - a vector of nu-merical attributes (“features”)\n",
        "- Timeseries data or sequence data\n",
        "    - Rank-3 tensors\n",
        "    - shape (samples, timesteps, features)\n",
        "    - sample\n",
        "        - a sequence (of length timesteps ) of feature vectors\n",
        "- Images—Rank\n",
        "    - 4 tensors\n",
        "    - shape (samples, height, width, channels)\n",
        "    - sample\n",
        "        - a 2D grid of pixels, and each pixel is represented by a vector of values (“channels”)\n",
        "- Video\n",
        "    - Rank-5 tensors\n",
        "        - shape (samples, frames, height, width, channels)\n",
        "        - sample\n",
        "            - a sequence (of length frames ) of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdKVbAQWMfV_"
      },
      "source": [
        "### 2.2.9 Vector data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPYB-k_Ae8pp"
      },
      "source": [
        "- each single data point can be encoded as a vector\n",
        "- a batch of data will be encoded as a rank-2 tensor \n",
        "- first axis is the samples axis and the second axis is the features axis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FDD-zAjMfWA"
      },
      "source": [
        "### 2.2.10 Timeseries data or sequence data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05umAbNSfCB2"
      },
      "source": [
        "- Data conatins\n",
        "    - time \n",
        "    - the notion of sequence order\n",
        "    - stores in\n",
        "        - rank-3 tensor with an explicit time axis. \n",
        "- Each sample can be encoded as a sequence of vectors (a rank-2tensor)\n",
        "- a batch of data will be encoded as a rank-3 tensor\n",
        "- The time axis is always the second axis (axis of index 1) by convention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-rOoR5WMfWA"
      },
      "source": [
        "### 2.2.11 Image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvd6pJE7fFqL"
      },
      "source": [
        "- Images\n",
        "    - three dimensions\n",
        "    - rank 3\n",
        "- Image data tensor\n",
        "    - rank 4\n",
        "    - channels-last convention\n",
        "    - channels-first convention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4N_aNKIMfWB"
      },
      "source": [
        "### 2.2.12 Video data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZMd4nPxfJiC"
      },
      "source": [
        "- Videos\n",
        "    - four dimensions\n",
        "    - rank 4\n",
        "- video data tensor\n",
        "    - rank 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g3ULCiMMfWB"
      },
      "source": [
        "## 2.3 The gears of neural networks: Tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zx_16NCfMxg"
      },
      "source": [
        "- all transformations learned by deep neural networks can be reduced to\n",
        "    - a handful of tensor operations (or tensor functions) \n",
        "    - applied to tensors of numeric data\n",
        "- \"keras.layers.Dense(512, activation=\"relu\")\"\n",
        "    - takes matrix as input\n",
        "    - return matrix as input\n",
        "    - output = relu(dot(input, W) + b)\n",
        "        - input a matrix\n",
        "        - W a matrix\n",
        "        - b a vector\n",
        "        - retu(x) = max(x,0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VeNRCZRNgNV"
      },
      "source": [
        "### 2.3.1 Element-wise operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEegq_23fRti"
      },
      "source": [
        "- Element wise operations\n",
        "  - relu operation\n",
        "  - addition / multiplication / subtraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vMz5DQiFOkme"
      },
      "outputs": [],
      "source": [
        "# relu implementation with python\n",
        "#  x is a rank-2 NumPy tensor\n",
        "def naive_relu(x):\n",
        "  assert len(x.shape) == 2\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] = max(x[i, j], 0)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CjOUBB4-O61w"
      },
      "outputs": [],
      "source": [
        "# addition implementation with python\n",
        "#  x is a rank-2 NumPy tensor\n",
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ruHVNMyNPoZo",
        "outputId": "702da7e7-ee8f-4389-dcf0-4d8e21ec6e6f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport numpy as np\\nz = x + y\\nz = np.maximum(z, 0.)\\n'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# relu and addition with numpy\n",
        "'''\n",
        "import numpy as np\n",
        "z = x + y\n",
        "z = np.maximum(z, 0.)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYuHgPNcPiMw",
        "outputId": "cd2a8e39-7c38-4142-dc90-6120623a62bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numpy Took: 0.01 s\n",
            "Python Took: 2.59 s\n"
          ]
        }
      ],
      "source": [
        "# time the difference\n",
        "import time\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.)\n",
        "print(\"Numpy Took: {0:.2f} s\".format(time.time() - t0))\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print(\"Python Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XxCY6FFQZ-l"
      },
      "source": [
        "### 2.3.2 Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_EcSAdAfW7R"
      },
      "source": [
        "- when applyting operations on two tensors with different size\n",
        "  - if there’s no ambiguity, the smaller tensor will be broadcast to match the shape of the larger tensor\n",
        "- Broadcasting steps\n",
        "  - Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
        "  - The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NOPi-tpRRfF",
        "outputId": "8b3e9353-b4a8-45a9-d8f6-12c9bc6d9acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape :  (20, 100)\n",
            "y shape :  (10,)\n",
            "y shape :  (1, 10)\n",
            "Y shape :  (32, 10)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "X = np.random.random((32, 10))\n",
        "y = np.random.random((10,))\n",
        "print(\"X shape : \",x.shape)\n",
        "print(\"y shape : \",y.shape)\n",
        "# both tensors are of diiferent shape\n",
        "# convert them to same shape\n",
        "y = np.expand_dims(y, axis=0)\n",
        "print(\"y shape : \",y.shape)\n",
        "Y = np.concatenate([y] * 32, axis=0)\n",
        "print(\"Y shape : \",Y.shape)\n",
        "# perform operation such as addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "xkTD3zEIStla"
      },
      "outputs": [],
      "source": [
        "# naive implementation\n",
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0z_mfKKIS03M"
      },
      "outputs": [],
      "source": [
        "# numpy do broadcasting by itself\n",
        "import numpy as np\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "z = np.maximum(x, y) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MusQFpuXTQo9"
      },
      "source": [
        "### 2.3.3 Tensor product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v4pBqMFfa60"
      },
      "source": [
        "- * is bitwise product\n",
        "- tensor ptoduct or dot product\n",
        "  - z = x • y\n",
        "  - vectors with the same number of elements are compatible for a dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEHcTzZTh1h",
        "outputId": "d6732927-fe5e-43f0-f606-30f9a5a7c42d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.949368961549895"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# numpy implemantion\n",
        "x = np.random.random((32,))\n",
        "y = np.random.random((32,))\n",
        "z = np.dot(x, y)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "H4cyT8FRTt7j"
      },
      "outputs": [],
      "source": [
        "# naive way\n",
        "def naive_vector_dot(x, y):\n",
        "    assert len(x.shape) == 1\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    z = 0.\n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i] * y[i]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Y0AdGUIPUG-y"
      },
      "outputs": [],
      "source": [
        "# dot product between matrix and vector\n",
        "def naive_matrix_vector_dot(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            z[i] += x[i, j] * y[j]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Fk0Gg9h-U6Sy"
      },
      "outputs": [],
      "source": [
        "# dot product between matrix and vector\n",
        "def naive_matrix_vector_dot(x, y):\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        z[i] = naive_vector_dot(x[i, :], y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k7e4eBxff4A"
      },
      "source": [
        "- if one of the two tensors has an ndim greater than 1, dot is no longer symmetric\n",
        "  - dot(x, y) isn’t the same as dot(y, x) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5ZZhIY_BVQrp"
      },
      "outputs": [],
      "source": [
        "# dot product between matrix and matrix\n",
        "  # dot(x, y) if and only if x.shape[1] == y.shape[0]\n",
        "def naive_matrix_dot(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 2\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros((x.shape[0], y.shape[1]))\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(y.shape[1]):\n",
        "            row_x = x[i, :]\n",
        "            column_y = y[:, j]\n",
        "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9sXZaDCV0U5"
      },
      "source": [
        "### 2.3.4 Tensor reshaping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiI9-9Fvfin5"
      },
      "source": [
        "- Tensor reshaping\n",
        "  - used when we preprocessed the digits data before feeding it into our model\n",
        "  - train_images = train_images.reshape((60000, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EMtZn51VQkq",
        "outputId": "412f112e-623d-4003-e068-0c14662fc866"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[0., 1.],\n",
        "             [2., 3.],\n",
        "             [4., 5.]])\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLIvM7eMWZpt",
        "outputId": "a0ea63aa-9298-4deb-9a23-6cc5d23b962e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       [5.]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = x.reshape((6, 1))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcpYlniYWcM8",
        "outputId": "618c3b9c-c3db-4a75-e3b5-c2483675fb44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 300)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# transposition / Transposing\n",
        "  # exchanging matrix its rows and its columns\n",
        "x = np.zeros((300, 20))\n",
        "x = np.transpose(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noe9P4ccWvPS"
      },
      "source": [
        "### 2.3.5 Geometric interpretation of tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YByXuhI1fr0_"
      },
      "source": [
        "- all tensor operations have a geometric interpretation\n",
        "- Translation\n",
        "  - addition applied to a set of points (such as a 2D object), this is called a “translation” \n",
        "- Rotation \n",
        "  - A counterclockwise rotation of a 2D vector by an angle theta\n",
        "    - dot product with a 2 × 2 matrix R = [[cos(theta), -sin(theta)], [sin(theta),cos(theta)]] .\n",
        "- Scaling\n",
        "  - A vertical and horizontal scaling of the image can be achieved\n",
        "    - dot prod\u0002uct with a 2 × 2 matrix S = [[horizontal_factor, 0], [0, vertical_factor]]\n",
        "- Linear transform\n",
        "  - A dot product with an arbitrary matrix implements a linear transform.\n",
        "- Affine transform\n",
        "  - An affine transform is the combination of \n",
        "    - a linear transform\n",
        "    - translation\n",
        "  - y = W • x + b\n",
        "  - Dense layer without an activation function is an affine layer.\n",
        "- Dense layer with relu activation\n",
        "  - An important observation about affine transforms is that if you ap\u0002ply many of them repeatedly, \n",
        "    - you still end up with an affine transform\n",
        "    - Let’s try it with two: \n",
        "      - affine2(affine1(x)) = W2 • (W1 • x + b1) + b2 = (W2 • W1) • x + (W2 • b1 + b2) . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be3Kt9SiZS3q"
      },
      "source": [
        "### 2.3.6 A geometric interpretation of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKLkSVh8fvss"
      },
      "source": [
        "- neural networks are chains of tensor operations\n",
        "- tensor opearions are geomatric transformation\n",
        "- machine learning\n",
        "  -  finding neat representations for complex, highly folded data manifolds in high-dimensional spaces\n",
        "- deep learning\n",
        "  - takes the approach of incrementally decomposing a complicated geometric transforma\u0002tion into a long chain of elementary ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEVoi1ol_Mdm"
      },
      "source": [
        "## 2.4 The engine of neural networks: Gradient-based optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZGvWItM_gnK"
      },
      "source": [
        "- each leayer output in the previous example\n",
        "  - `output = relu(dot(input, W) + b)`\n",
        "  - W and b \n",
        "    - are tensors\n",
        "    - are attributes of the layer. \n",
        "    - weights or trainable parameters of the layer\n",
        "    - W is kernel attributes\n",
        "    - b is bias attributes\n",
        "    - weights contain the information learned by the model from exposure to training data.\n",
        "- random initialization\n",
        "  - weight matrices are filled with small random values\n",
        "- training\n",
        "  - gradually adjusting weights, based on a feedback signal.\n",
        "- Working of training loop\n",
        "  1. Draw a batch of training samples, x , and corresponding targets, y_true .\n",
        "  2. Run the model on x (a step called the forward pass) to obtain predictions, y_pred .\n",
        "  3. Compute the loss of the model on the batch, a measure of the mismatch between y_pred and y_true .\n",
        "  4. Update all weights of the model in a way that slightly reduces the loss on this batch.\n",
        "- How to update weights\n",
        "  1. freeze all weights and compute based on any one and then repeat for all weights consuming lot of resources\n",
        "  2. gradient method\n",
        "    - describe how the loss varies as you move the model’s coefficients in different directions. \n",
        "    - Compute gradient of loss and use it to move the coefficients at once in a single update in a direction that decreases the loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwV6PAPVnQ6P"
      },
      "source": [
        "### 2.4.1 What’s a derivative?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_eJChAOnUAN"
      },
      "source": [
        "- continuity\n",
        "  - small change in one quantity results a small change in other\n",
        "- derivative\n",
        "  - `f(x) = y`\n",
        "  - `f(x + epsilon_x) = y + a * epsilon_x`\n",
        "    - epsilon_x is small change in x\n",
        "    - a is slope\n",
        "      - -ve a, increase in x decrease in f(x)\n",
        "      - +ve a, increase in x increase in f(x)\n",
        "- optimization\n",
        "  - finding values of x that minimize the value of f(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBW2gLv5o8-N"
      },
      "source": [
        "### 2.4.2 Derivative of a tensor operation: The gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "916HII2EpAEu"
      },
      "source": [
        "- gradient\n",
        "  - The derivative of a tensor operation (or tensor function)\n",
        "  - The concept of derivation can be applied to any such function, as long as the surfaces they describe are\n",
        "continuous and smooth.\n",
        "  - derivative represents the local slope of the curve of the function\n",
        "  - the gradient of a tensor function represents the curvature of the multidimensional surface described by the function.\n",
        "    - It characterizes how the output of the function varies when its input parameters vary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cvWjPtbqmZo"
      },
      "source": [
        "### 2.4.3 Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is1dFfOvqomg"
      },
      "source": [
        "- a function’s minimum is a point where the derivative is 0\n",
        "- modify the parameters little by little based on the current loss value for a random batch of data\n",
        "- learning rate\n",
        "  - a scalar factor modulating the “speed” of the gradient descent process\n",
        "  - too small, the descent down the curve will take many iterations, and it could get stuck in a local minimum.\n",
        "  - too large, your updates may end up taking you to completely random locations on the curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFufxwuisvSW"
      },
      "source": [
        "### 2.4.4 Chaining derivatives: The Backpropagation algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USldim5Jsw7I"
      },
      "source": [
        "- THE CHAIN RULE\n",
        "  - Backpropagation is a way to use the derivatives of simple operations (such as addition, relu, or tensor\n",
        "product) to easily compute the gradient of arbitrarily complex combinations of these atomic operations.\n",
        "  - Applying the chain rule to the computation of the gradient values of a neural network gives rise to an algorithm called backpropagation\n",
        "- AUTOMATIC DIFFERENTIATION WITH COMPUTATION GRAPHS\n",
        "  - A computation graph is the data structure at the heart of TensorFlow and the deep learning revolution in general. \n",
        "  - It’s a directed acyclic graph of operations in our case, tensor operations. \n",
        "  - Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, computing the contribution that each parameter had in the loss value\n",
        "- THE GRADIENT TAPE IN TENSORFLOW\n",
        "  - The API through which you can leverage TensorFlow’s powerful automatic differentiation capabilities is the GradientTape\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwe1MGzKw9gv"
      },
      "source": [
        "### Gradient-based optimization\n",
        "![Gradient-based optimization](./snaps/one.jpg)\n",
        "\n",
        "![Gradient-based optimization](./snaps/two.jpg)\n",
        "\n",
        "![Gradient-based optimization](./snaps/three.jpg)\n",
        "\n",
        "![Gradient-based optimization](./snaps/four.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPIxUFghxOV7"
      },
      "source": [
        "## 2.5 Looking back at our first example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D8yMWzBxbME"
      },
      "source": [
        "- the model\n",
        "\n",
        "  ![Model](./snaps/five.png)\n",
        "  - layers that are chained together\n",
        "  - maps the input data to predictions\n",
        "  - The loss function compares these predictions to the targets, producing a loss value: \n",
        "    - a measure of how well the model’s predictions match what was expected.\n",
        "  - The optimizer uses this loss value to update the model’s weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "iHoWsCJ-yY8d",
        "outputId": "d710bd1e-d79d-4715-db7d-8b7989b3547f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\\ntrain_images = train_images.reshape((60000, 28 * 28))\\ntrain_images = train_images.astype(\"float32\") / 255\\ntest_images = test_images.reshape((10000, 28 * 28))\\ntest_images = test_images.astype(\"float32\") / 255\\n'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Input Data\n",
        "'''\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddEa_U6yyi1f"
      },
      "source": [
        "- input images are stored in NumPy tensors\n",
        "  - formatted as\n",
        "    - float32 tensors of shape (60000, 784) (training data) and (10000, 784) (test data) respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zFmC4sIPydGf",
        "outputId": "ba8dfe7a-ebf3-4366-ff61-46316330de53"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmodel = keras.Sequential([\\n  layers.Dense(512, activation=\"relu\"),\\n  layers.Dense(10, activation=\"softmax\")\\n])\\n'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model\n",
        "'''\n",
        "model = keras.Sequential([\n",
        "  layers.Dense(512, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3jmImrTyvoO"
      },
      "source": [
        "- two Dense layers\n",
        "  - each layer applies a few simple tensor operations to the input data\n",
        "  - these operations involve weight tensors. \n",
        "- Weight tensors, which are attributes of the layers, are where the knowledge of the model persists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5dvU2oF6zE4X",
        "outputId": "4c15cc39-e57c-4134-c75e-0365d2324ba6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmodel.compile(\\n  optimizer=\"rmsprop\",\\n  loss=\"sparse_categorical_crossentropy\",\\n  metrics=[\"accuracy\"])\\n'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compilation\n",
        "'''\n",
        "model.compile(\n",
        "  optimizer=\"rmsprop\",\n",
        "  loss=\"sparse_categorical_crossentropy\",\n",
        "  metrics=[\"accuracy\"])\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73wj1pB2zDrv"
      },
      "source": [
        "- sparse_categorical_crossentropy is the loss function that’s used as a feedback signal for learning the weight tensors, and which the training phase will attempt to minimize.\n",
        "- reduction of the loss happens via mini-batch stochastic gradient descent.\n",
        "- The exact rules governing a specific use of gradient descent are defined by the rmsprop optimizer passed as the first argument.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K4cb2GypznEB",
        "outputId": "9610615e-d74a-47b4-ccfa-7e338d031ceb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmodel.fit(train_images, train_labels, epochs=5, batch_size=128)\\n'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# training loop\n",
        "'''\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj97uWi00CGG"
      },
      "source": [
        "- the model will start to iterate on the training data in mini-batches of 128 samples, 5 times over"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhGBm3Zx0O-i"
      },
      "source": [
        "### 2.5.1 Reimplementing our first example from scratch in TensorFlow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8suR8xnU0a9O"
      },
      "source": [
        "#### A SIMPLE DENSE CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "zbwBnfhl0PwE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmEzaDTm0-y3"
      },
      "source": [
        "#### A SIMPLE SEQUENTIAL CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "SoAIze3e1Gup"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "           x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "       weights = []\n",
        "       for layer in self.layers:\n",
        "           weights += layer.weights\n",
        "       return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bGjDibM1Nsf"
      },
      "source": [
        "#### MOCK KERAS MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "qLpma0PI1Ppj"
      },
      "outputs": [],
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceej3-k81ZFU"
      },
      "source": [
        "#### A BATCH GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "KXIB9KbZ1eEy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UvLC0l61dtX"
      },
      "source": [
        "### 2.5.2 Running one training step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zo6DlDP1wur"
      },
      "source": [
        "- updating the weights of the model after running it on one batch of data. We need to\n",
        "  1. Compute the predictions of the model for the images in the batch.\n",
        "  2. Compute the loss value for these predictions, given the actual labels.\n",
        "  3. Compute the gradient of the loss with regard to the model’s weights.\n",
        "  4. Move the weights by a small amount in the direction opposite to the gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "y8xVDW132TQx"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ATKiB1hI2mXy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "l9xcuCmn2D-w"
      },
      "outputs": [],
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions)\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5wncU7U2tkT"
      },
      "source": [
        "### 2.5.3 The full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "PVxwNSVH2Pjs"
      },
      "outputs": [],
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbDuWLjd23wl",
        "outputId": "f258745f-f09a-4208-f7de-c56faa52cf3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "loss at batch 0: 5.69\n",
            "loss at batch 100: 2.25\n",
            "loss at batch 200: 2.17\n",
            "loss at batch 300: 2.09\n",
            "loss at batch 400: 2.20\n",
            "Epoch 1\n",
            "loss at batch 0: 1.91\n",
            "loss at batch 100: 1.89\n",
            "loss at batch 200: 1.79\n",
            "loss at batch 300: 1.71\n",
            "loss at batch 400: 1.81\n",
            "Epoch 2\n",
            "loss at batch 0: 1.58\n",
            "loss at batch 100: 1.59\n",
            "loss at batch 200: 1.47\n",
            "loss at batch 300: 1.43\n",
            "loss at batch 400: 1.50\n",
            "Epoch 3\n",
            "loss at batch 0: 1.32\n",
            "loss at batch 100: 1.35\n",
            "loss at batch 200: 1.22\n",
            "loss at batch 300: 1.21\n",
            "loss at batch 400: 1.27\n",
            "Epoch 4\n",
            "loss at batch 0: 1.12\n",
            "loss at batch 100: 1.16\n",
            "loss at batch 200: 1.03\n",
            "loss at batch 300: 1.05\n",
            "loss at batch 400: 1.11\n",
            "Epoch 5\n",
            "loss at batch 0: 0.98\n",
            "loss at batch 100: 1.02\n",
            "loss at batch 200: 0.89\n",
            "loss at batch 300: 0.93\n",
            "loss at batch 400: 0.99\n",
            "Epoch 6\n",
            "loss at batch 0: 0.87\n",
            "loss at batch 100: 0.92\n",
            "loss at batch 200: 0.79\n",
            "loss at batch 300: 0.84\n",
            "loss at batch 400: 0.91\n",
            "Epoch 7\n",
            "loss at batch 0: 0.79\n",
            "loss at batch 100: 0.83\n",
            "loss at batch 200: 0.71\n",
            "loss at batch 300: 0.77\n",
            "loss at batch 400: 0.84\n",
            "Epoch 8\n",
            "loss at batch 0: 0.73\n",
            "loss at batch 100: 0.76\n",
            "loss at batch 200: 0.65\n",
            "loss at batch 300: 0.72\n",
            "loss at batch 400: 0.79\n",
            "Epoch 9\n",
            "loss at batch 0: 0.68\n",
            "loss at batch 100: 0.71\n",
            "loss at batch 200: 0.60\n",
            "loss at batch 300: 0.67\n",
            "loss at batch 400: 0.75\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkjgcjDd2_VT"
      },
      "source": [
        "### 2.5.4 Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsGLn5fG3OXR",
        "outputId": "d61ebf99-de74-4d0e-caf9-253fb61914f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.82\n"
          ]
        }
      ],
      "source": [
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Tensors form the foundation of modern machine learning systems. They come in various flavors of dtype , rank , and shape .\n",
        "- You can manipulate numerical tensors via tensor operations (such as addition, tensor product, or element-wise multiplication) which can be interpreted as encoding geometric transformations. In general, everything in deep learning is amenable to a geometric interpretation.\n",
        "- Deep learning models consist of chains of simple tensor operations, parameterized by weights, which are themselves tensors. The weights of a model are where its “knowledge” is stored.\n",
        "- Learning means finding a set of values for the model’s weights that minimizes a loss function for a given set of training data samples and their corresponding targets.\n",
        "- Learning happens by drawing random batches of data samples and their targets, and computing the gradient of the model parameters with respect to the loss on the batch. The model parameters are then moved a bit (the magnitude of the move is defined by the learning rate) in the opposite direction from the gradient. This is called mini-batch stochastic gradient descent.\n",
        "- The entire learning process is made possible by the fact that all tensor operations in neural networks are differentiable, and thus it’s possible to apply the chain rule of derivation to find the gradient function mapping the current parameters and current batch of data to a gradient value. This is called backpropagation.\n",
        "- Two key concepts you’ll see frequently in future chapters are loss and optimizers. These are the two things you need to define before you begin feeding data into a model.\n",
        "    - The loss is the quantity you’ll attempt to minimize during training, so it should represent a measure of success for the task you’re trying to solve.\n",
        "    - The optimizer specifies the exact way in which the gradient of the loss will be used to update parameters: for instance, it could be the RMSProp optimizer, SGD with momentum, and so on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmrM-6Bf3n8F"
      },
      "source": [
        "#### End"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
