{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Nasir Hussain - 2021/02/07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 What is deep learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Artificial intelligence, machine learning, and deep learning\n",
    "\n",
    "![Artificial intelligence, machine learning, and deep learning](./snaps/one.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Artificial intelligence\n",
    "- AI can be described as the effort to automate intellectual tasks normally performed by humans.\n",
    "    - Symbolic AI\n",
    "    - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Machine learning\n",
    "- Analytical Engine: the first-known general-purpose mechanical computer\n",
    "- The Analytical Engine has no pretensions whatever to originate anything. It can do whatever we know how to order it to perform. . . . Its province is to assist us in making available what we’re already acquainted with.\n",
    "- Turing test\n",
    "- the machine looks at the input data and the corresponding answers, and figures out what the rules should be\n",
    "- A machine learning system is trained rather than explicitly programmed.\n",
    "- When dealing with large, complex datasets - classical statistical analysis such as Bayesian analysis would be impractical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning: a new programming paradigm](./snaps/two.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Learning rules and representations from data\n",
    "- deep learning\n",
    "- what machine learning algorithms do\n",
    "- Requirements for machine learning\n",
    "    - Input data points\n",
    "        - For instance, if the task is speech recognition, these data points could be sound files of people speaking. If the task is image tagging, they could be pictures.\n",
    "    - Examples of the expected output\n",
    "        - In a speech-recognition task, these could be human-generated transcripts of sound files. In an image task, expected outputs could be tags such as “dog,” “cat,” and so on.\n",
    "    - A way to measure whether the algorithm is doing a good job\n",
    "        - This is necessary in order to determine the distance between the algorithm’s current output and its expected output. The measurement is used as a feedback signal to adjust the way the algorithm works. This adjustment step is what we call learning.\n",
    "- machine learning model transforms its input data into meaningful outputs\n",
    "- the central problem in machine learning and deep learning is to meaningfully transform data\n",
    "    - representations\n",
    "        - a different way to look at data\n",
    "        - to represent or encode data.\n",
    "    - Machine learning models are all about finding appropriate representations for their input data\n",
    "- Learning\n",
    "    - in the context of machine learning, describes an automatic search process for data transformations that produce useful representations\n",
    "- Machine learning algorithms aren’t usually creative in finding these transformations; they’re merely searching through a predefined set of operations, called a hypothesis space.\n",
    "- searching for useful representations and rules over some input data, within a predefined space of possibilities, using guidance from a feedback signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 The “deep” in “deep learning”\n",
    "- successive layers\n",
    "- “deep” in “deep learning”\n",
    "    - stands for this idea of successive layers of representations\n",
    "- layered representations learning or hierarchical representations learning\n",
    "- shallow learning\n",
    "- neural networks\n",
    "- deep learning is a mathematical framework for learning representations from data\n",
    "- purified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Understanding how deep learning works, in three figures\n",
    "- layer does to its input data is stored in the layer’s weights\n",
    "- transformation\n",
    "    - parameterized by its weights\n",
    "- learning means finding a set of values for the weights of all layers in a network\n",
    "- loss function / objective function / cost function.\n",
    "- optimizer / Backpropagation \n",
    "- training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The loss score is used as a feedback signal to adjust the weights.](./snaps/three.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 What deep learning has achieved so far\n",
    "- Near-human-level image classification\n",
    "- Near-human-level speech transcription\n",
    "- Near-human-level handwriting transcription\n",
    "- Dramatically improved machine translation\n",
    "- Dramatically improved text-to-speech conversion\n",
    "- Digital assistants such as Google Assistant and Amazon Alexa\n",
    "- Near-human-level autonomous driving\n",
    "- Improved ad targeting, as used by Google, Baidu, or Bing\n",
    "- Improved search results on the web\n",
    "- Ability to answer natural language questions\n",
    "- Superhuman Go playing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7 Don’t believe the short-term hype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.8 The promise of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Before deep learning: A brief history of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep learning isn’t always the right tool for the job—sometimes there isn’t enough data for deep learning to be applicable, and sometimes the problem is better solved by a different algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Probabilistic modeling\n",
    "- Probabilistic modeling\n",
    "- Naive Bayes algorithm\n",
    "- assuming that the features in the input data are all independent\n",
    "- logistic regression\n",
    "-  classification algorithm rather than a regression algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Early neural networks\n",
    "- Backpropagation algorithm—a way to train chains of parametric operations using gradient-descent optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Kernel methods\n",
    "- Kernel methods are a group of classification algorithms, the best known of which is the Support Vector Machine (SVM).\n",
    "- SVM is a classification algorithm that works by finding “decision boundaries” separating two classes\n",
    "    1. The data is mapped to a new high-dimensional representation where the decision boundary can be expressed as a hyperplane\n",
    "    2. A good decision boundary (a separation hyperplane) is computed by trying to maximize the distance between the hyperplane and the closest data points from each class, a step called maximizing the margin. This allows the boundary to generalize well to new samples outside of the training dataset\n",
    "-  A kernel function is a computationally tractable operation that maps any two points in your initial space to the distance between these points in your target representation space, completely bypassing the explicit computation of the new representa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Decision trees, random forests, and gradient boosting machines\n",
    "- Decision trees are flowchart-like structures\n",
    "- Random Forest algorithm\n",
    "- gradient boosting machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![decision tree](./snaps/four.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Back to neural networks\n",
    "- \"Top-five accuracy\" measures how often the model selects the correct answer as part of its top five guesses (out of 1,000 possible answers, in the case of ImageNet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 What makes deep learning different\n",
    "- deep learning\n",
    "- automates\n",
    "- feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 The modern machine learning landscape\n",
    "- gradient boosted trees, for shallow-learning problems\n",
    "- deep learning, for perceptual problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Why deep learning? Why now?\n",
    "### 1.3.1 Hardware\n",
    "### 1.3.2 Data\n",
    "### 1.3.3 Algorithms\n",
    "- Better activation functions for neural layers\n",
    "- Better weight-initialization schemes, starting with layer-wise pretraining, which was then quickly abandoned\n",
    "- Better optimization schemes, such as RMSProp and Adam\n",
    "### 1.3.4 A new wave of investment\n",
    "### 1.3.5 The democratization of deep learning\n",
    "### 1.3.6 Will it last?\n",
    "- Simplicity\n",
    "    - Deep learning removes the need for feature engineering, replacing complex, brittle, engineering-heavy pipelines with simple, end-to-end trainable models that are typically built using only five or six different tensor operations.\n",
    "- Scalability\n",
    "    - Deep learning is highly amenable to parallelization on GPUs or TPUs, so it can take full advantage of Moore’s law. In addition, deep learning models are trained by iterating over small batches of data, allowing them to be trained on datasets of arbitrary size. (The only bottleneck is the amount of parallel computational power available, which, thanks to Moore’s law, is a fast-moving barrier.)\n",
    "- Versatility and reusability\n",
    "    - Unlike many prior machine learning approaches, deep learning models can be trained on additional data without restarting from scratch, making them viable for continuous online learning—an important property for very large production models. Furthermore, trained deep learning models are repurposable and thus reusable: for instance, it’s possible to take a deep learning model trained for image classification and drop it into a video-processing pipeline. This allows us to reinvest previous work into increasingly complex and powerful models. This also makes deep learning applicable to fairly small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
