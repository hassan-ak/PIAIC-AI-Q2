{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning - Nasir Hussain - 2021/03/06"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNWhMhEYrSCe"
      },
      "source": [
        "# 4 Getting started with neural networks: Classification and regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jt5alYmrPha"
      },
      "source": [
        "## 4.2 Classifying newswires: A multiclass classification example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZDRSuzerPc8"
      },
      "source": [
        "- multiclass classification\n",
        "  - single-label multiclass classification\n",
        "    - each input sample should be categorized into more than two categories\n",
        "  - multi-label multiclass classification\n",
        "    - each input sample can be assigned multiple labels  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu3jB4W1rPZk"
      },
      "source": [
        "### 4.2.1 The Reuters dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX_GuSjYrPWW"
      },
      "source": [
        "- Reuters dataset\n",
        "  - set of short newswires and their topics\n",
        "  - used for test classification\n",
        "  - 46 topics\n",
        "    - atleast 10 examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JlDUSoibrNuJ"
      },
      "outputs": [],
      "source": [
        "# Listing 4.11 Loading the Reuters dataset\n",
        "from tensorflow.keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klbuW1MRvGDR"
      },
      "source": [
        "- num_words=10000 \n",
        "  - restricts the data to the 10,000 most frequently occurring words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5rW6DQXvgjl",
        "outputId": "85e403f8-9d48-4b1c-8ad5-099b5172bd26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training data :  (8982,)\n",
            "Shape of training labels :  (8982,)\n",
            "Shape of testing data :  (2246,)\n",
            "Shape of training labels :  (2246,)\n"
          ]
        }
      ],
      "source": [
        "# shape of data\n",
        "print(\"Shape of training data : \",train_data.shape)\n",
        "print(\"Shape of training labels : \",train_labels.shape)\n",
        "print(\"Shape of testing data : \",test_data.shape)\n",
        "print(\"Shape of training labels : \",test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy_4QRXCv-hI"
      },
      "source": [
        "- training data is of length 8982\n",
        "- test data is of length 2246\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9THuXeEwS8T",
        "outputId": "ad891549-9f9f-4e06-d8f0-104082397a29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1st news from training data :  [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "1st label from training data :  3\n",
            "1st news from testing data :  [1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
            "1st label from testing data :  3\n",
            "Unique labels :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n"
          ]
        }
      ],
      "source": [
        "# samples of data\n",
        "import numpy as np\n",
        "print(\"1st news from training data : \",train_data[0])\n",
        "print(\"1st label from training data : \",train_labels[0])\n",
        "print(\"1st news from testing data : \",test_data[0])\n",
        "print(\"1st label from testing data : \",test_labels[0])\n",
        "print(\"Unique labels : \",np.unique(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_NzMuGnwsrh",
        "outputId": "d25700f5-c027-4196-a46a-da1e62e718d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum number in any sequence :  9999\n"
          ]
        }
      ],
      "source": [
        "# find max value from sequence\n",
        "print(\"Maximum number in any sequence : \",max([max(sequence) for sequence in train_data]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O8N3KH8w0Zd",
        "outputId": "368ec61e-aeed-4eef-fbc5-7ab64c2de5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1st news from training data :  ? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ]
        }
      ],
      "source": [
        "# Listing 4.12 Decoding newswires back to text\n",
        "# load word index\n",
        "word_index = reuters.get_word_index()\n",
        "# reverse the dic so numbers come first and then word\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# 0, 1, and 2 are reserved indices for “padding,” “start of sequence,” and “unknown.”\n",
        "decoded_newswire = \" \".join([reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])\n",
        "print(\"1st news from training data : \",decoded_newswire)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSukuX4ovKuz"
      },
      "source": [
        "### 4.2.2 Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LnOmaspyH7B"
      },
      "source": [
        "- as we set the max number of words to 10000, so it is necessary to have all the data of same size\n",
        "  - vectorize the data to do so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H4EiClyiyeiZ"
      },
      "outputs": [],
      "source": [
        "# Listing 4.13 Encoding the input data\n",
        "import numpy as np \n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    for j in sequence:\n",
        "      results[i, j] = 1.\n",
        "  return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "986_PRRhx_wp"
      },
      "source": [
        "- vectorize the labels\n",
        "  - cast the label list as an integer tensor\n",
        "  - one-hot encoding / categorical encoding\n",
        "    - embedding each label as an allzero vector with a 1 in the place of the label index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jaQqXtD91QmV"
      },
      "outputs": [],
      "source": [
        "# Listing 4.14 Encoding the labels\n",
        "def to_one_hot(labels, dimension=np.unique(train_labels).size):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels):\n",
        "    results[i, label] = 1.\n",
        "  return results\n",
        "y_train = to_one_hot(train_labels)\n",
        "y_test = to_one_hot(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdKGbsZh2u9U"
      },
      "source": [
        "- built in method for one hot encoding\n",
        "  ```.ipynb\n",
        "  from tensorflow.keras.utils import to_categorical\n",
        "  y_train = to_categorical(train_labels)\n",
        "  y_test = to_categorical(test_labels)\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc51X0Yi1uRm",
        "outputId": "b36fb706-4b50-4dbe-b2a2-a6729a934933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1st news from training data after vectorization :  [0. 1. 1. ... 0. 0. 0.]\n",
            "1st label from training data after vectorization:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "1st news from testing data after vectorization:  [0. 1. 1. ... 0. 0. 0.]\n",
            "1st label from testing data after vectorization:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# samples of data\n",
        "print(\"1st news from training data after vectorization : \",x_train[0])\n",
        "print(\"1st label from training data after vectorization: \",y_train[0])\n",
        "print(\"1st news from testing data after vectorization: \",x_test[0])\n",
        "print(\"1st label from testing data after vectorization: \",y_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBxAWIlF3D86"
      },
      "source": [
        "### 4.2.3 Building your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvrIeBf3C_ZP"
      },
      "source": [
        "- each layer can only access information present in the output of the previous layer.\n",
        "- if one layer drops some information relevant to the classification problem, this information can never be recovered by later layers\n",
        "- each layer can potentially become an information bottleneck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MryM-GUlCSGT"
      },
      "outputs": [],
      "source": [
        "# Listing 4.15 Model definition\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(46, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYbFZga3DlVr"
      },
      "source": [
        "- output\n",
        "  - a 46-dimensional vector\n",
        "    - Each entry in this vector (each dimension) will encode a different output class.\n",
        "  - softmax\n",
        "    - output a probability distribution over the 46 different output classes\n",
        "- loss function\n",
        "  - categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t4kLlzNUEMyf"
      },
      "outputs": [],
      "source": [
        "# Listing 4.16 Compiling the model\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnHoON1GEMVs"
      },
      "source": [
        "### 4.2.4 Validating your approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhi3UAsdEgug"
      },
      "source": [
        "- select 1000 samples as validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cri6UhpaEYRy"
      },
      "outputs": [],
      "source": [
        "# Listing 4.17 Setting aside a validation set\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9tmwE9ZEk87"
      },
      "source": [
        "- use 20 apoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE0myjW2Ese3",
        "outputId": "e7da6a6e-2799-4266-aba2-3a84b053cc32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 3s 58ms/step - loss: 2.6159 - accuracy: 0.5361 - val_loss: 1.7125 - val_accuracy: 0.6520\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 1.4145 - accuracy: 0.7080 - val_loss: 1.3017 - val_accuracy: 0.7150\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.0556 - accuracy: 0.7783 - val_loss: 1.1195 - val_accuracy: 0.7560\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.8371 - accuracy: 0.8207 - val_loss: 1.0352 - val_accuracy: 0.7790\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.6698 - accuracy: 0.8539 - val_loss: 0.9568 - val_accuracy: 0.7990\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.5326 - accuracy: 0.8901 - val_loss: 0.9036 - val_accuracy: 0.8100\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.4263 - accuracy: 0.9112 - val_loss: 0.8920 - val_accuracy: 0.8160\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.3483 - accuracy: 0.9268 - val_loss: 0.8870 - val_accuracy: 0.8120\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2846 - accuracy: 0.9386 - val_loss: 0.9362 - val_accuracy: 0.7970\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.2454 - accuracy: 0.9440 - val_loss: 0.8956 - val_accuracy: 0.8110\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.2072 - accuracy: 0.9485 - val_loss: 0.9219 - val_accuracy: 0.8040\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1819 - accuracy: 0.9508 - val_loss: 0.9357 - val_accuracy: 0.8100\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1626 - accuracy: 0.9536 - val_loss: 0.9739 - val_accuracy: 0.8060\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1521 - accuracy: 0.9548 - val_loss: 0.9739 - val_accuracy: 0.8100\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.1366 - accuracy: 0.9569 - val_loss: 1.0173 - val_accuracy: 0.7970\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.1307 - accuracy: 0.9567 - val_loss: 0.9918 - val_accuracy: 0.8000\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1256 - accuracy: 0.9570 - val_loss: 1.0616 - val_accuracy: 0.8040\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.1200 - accuracy: 0.9568 - val_loss: 1.0740 - val_accuracy: 0.8030\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1126 - accuracy: 0.9568 - val_loss: 1.0928 - val_accuracy: 0.8020\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1130 - accuracy: 0.9548 - val_loss: 1.0874 - val_accuracy: 0.7990\n"
          ]
        }
      ],
      "source": [
        "# Listing 4.18 Training the model\n",
        "history = model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=512,\n",
        "    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFtCVaXfEscC",
        "outputId": "86ce38e8-eda3-455f-fa25-0c1fa5e2545c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "History of model fitting : \n",
            "{'loss': [2.615912437438965, 1.414499282836914, 1.0555920600891113, 0.8371384739875793, 0.6697941422462463, 0.5326083302497864, 0.42627617716789246, 0.34830474853515625, 0.284557580947876, 0.24535612761974335, 0.20722812414169312, 0.18185973167419434, 0.1626042127609253, 0.15205544233322144, 0.13662931323051453, 0.13065601885318756, 0.12557512521743774, 0.11996189504861832, 0.11258159577846527, 0.11300548911094666], 'accuracy': [0.5360811948776245, 0.7079679369926453, 0.778251051902771, 0.8207216262817383, 0.8539212942123413, 0.8901277780532837, 0.9111751317977905, 0.9268353581428528, 0.9386118650436401, 0.9439989924430847, 0.948509156703949, 0.9507642388343811, 0.9536457061767578, 0.9547732472419739, 0.9569030404090881, 0.9566524624824524, 0.957028329372406, 0.9567777514457703, 0.9567777514457703, 0.9547732472419739], 'val_loss': [1.7125048637390137, 1.3016828298568726, 1.1195275783538818, 1.0352444648742676, 0.9567606449127197, 0.9036373496055603, 0.8920026421546936, 0.8869519233703613, 0.9361657500267029, 0.8956114649772644, 0.9218757152557373, 0.9356576204299927, 0.973908007144928, 0.973882794380188, 1.0172940492630005, 0.9918100833892822, 1.0615793466567993, 1.0739727020263672, 1.0928049087524414, 1.0874484777450562], 'val_accuracy': [0.6520000100135803, 0.7149999737739563, 0.7559999823570251, 0.7789999842643738, 0.7990000247955322, 0.8100000023841858, 0.8159999847412109, 0.8119999766349792, 0.796999990940094, 0.8109999895095825, 0.8040000200271606, 0.8100000023841858, 0.8059999942779541, 0.8100000023841858, 0.796999990940094, 0.800000011920929, 0.8040000200271606, 0.8029999732971191, 0.8019999861717224, 0.7990000247955322]}\n",
            "dictonary keys : \n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ],
      "source": [
        "# check history object\n",
        "print(\"History of model fitting : \")\n",
        "history_dict = history.history\n",
        "print(history_dict)\n",
        "print(\"dictonary keys : \")\n",
        "print(history_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2pmzPUX1EsYg"
      },
      "outputs": [],
      "source": [
        "# Listing 4.19 Plotting the training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_loss(historyDic):\n",
        "  history_dict = historyDic.history\n",
        "  loss_values = history_dict[\"loss\"]\n",
        "  val_loss_values = history_dict[\"val_loss\"]\n",
        "  epochs = range(1, len(loss_values) + 1)\n",
        "  plt.clf()\n",
        "  plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "  plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "  plt.title(\"Training and validation loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "d6pBEhWtEsVO",
        "outputId": "38313fe5-e8c8-4133-b302-4711255f5ca1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU5bn38e/NJsuwyKIgCANRUQkywAAqiqjJiaJxQaISXoUYRTjuGpcjiXpMOCcxJsdD3EJUXDIRE/UQF4zGFQyJcUBEUIzbYDCIiMKAIDJwv388NUwzdM/0MFPdPdO/z3XV1dXVVdV31/TU3c9ST5m7IyIi+atZtgMQEZHsUiIQEclzSgQiInlOiUBEJM8pEYiI5DklAhGRPKdEIA3KzJ4ys4kNvW42mVmZmX0jhv26me0Xzd9pZj9KZ93deJ8JZvbM7sZZw35Hm9nKht6vZF6LbAcg2WdmGxOetgW2ANui5+e7e0m6+3L34+NYt6lz9ykNsR8zKwQ+AFq6e0W07xIg7b+h5B8lAsHdCyrnzawMONfdn62+npm1qDy5iEjToaohSamy6G9mV5vZx8AsM9vTzJ4wszVm9nk03ythmxfN7NxofpKZvWxmN0frfmBmx+/mun3NbJ6ZbTCzZ83sNjP7bYq404nxx2b2l2h/z5hZ14TXzzKzFWa21sym1XB8RpjZx2bWPGHZqWa2JJofbmZ/NbN1ZrbKzG41s1Yp9nWvmf0k4fmV0Tb/MrNzqq17gpm9ZmblZvZPM7sh4eV50eM6M9toZodVHtuE7Q83s1fNbH30eHi6x6YmZnZQtP06M1tmZiclvDbGzN6M9vmRmf0gWt41+vusM7PPzGy+mem8lGE64FKb7kBnoA8wmfCdmRU97w1sBm6tYfsRwNtAV+Am4G4zs91Y93fA34EuwA3AWTW8Zzoxfhf4HrAX0AqoPDEdDNwR7X+f6P16kYS7vwJ8ARxTbb+/i+a3AZdFn+cw4Fjg32uImyiG46J4vgnsD1Rvn/gCOBvoBJwATDWzU6LXRkWPndy9wN3/Wm3fnYEngRnRZ/sl8KSZdan2GXY5NrXE3BJ4HHgm2u4ioMTM+ker3E2oZmwPfB14Plp+BbAS6AbsDVwLaNybDFMikNpsB6539y3uvtnd17r7I+6+yd03ANOBo2rYfoW7/8bdtwH3AT0I//Bpr2tmvYFhwHXu/pW7vww8luoN04xxlrv/w903A78HiqLl44An3H2eu28BfhQdg1QeBMYDmFl7YEy0DHdf6O5/c/cKdy8Dfp0kjmROj+Jb6u5fEBJf4ud70d3fcPft7r4ker909gshcbzj7g9EcT0ILAe+nbBOqmNTk0OBAuCn0d/oeeAJomMDbAUONrMO7v65uy9KWN4D6OPuW919vmsAtIxTIpDarHH3LyufmFlbM/t1VHVSTqiK6JRYPVLNx5Uz7r4pmi2o47r7AJ8lLAP4Z6qA04zx44T5TQkx7ZO47+hEvDbVexF+/Y81sz2AscAid18RxXFAVO3xcRTHfxFKB7XZKQZgRbXPN8LMXoiqvtYDU9Lcb+W+V1RbtgLomfA81bGpNWZ3T0yaifs9jZAkV5jZS2Z2WLT858C7wDNm9r6ZXZPex5CGpEQgtan+6+wKoD8wwt07UFUVkaq6pyGsAjqbWduEZfvWsH59YlyVuO/oPbukWtnd3ySc8I5n52ohCFVMy4H9oziu3Z0YCNVbiX5HKBHt6+4dgTsT9lvbr+l/EarMEvUGPkojrtr2u2+1+v0d+3X3V939ZEK10RxCSQN33+DuV7h7P+Ak4HIzO7aesUgdKRFIXbUn1Lmvi+qbr4/7DaNf2KXADWbWKvo1+e0aNqlPjA8DJ5rZEVHD7o3U/n/yO+ASQsL5Q7U4yoGNZnYgMDXNGH4PTDKzg6NEVD3+9oQS0pdmNpyQgCqtIVRl9Uux77nAAWb2XTNrYWZnAAcTqnHq4xVC6eEqM2tpZqMJf6PZ0d9sgpl1dPethGOyHcDMTjSz/aK2oPWEdpWaquIkBkoEUle3AG2AT4G/AX/K0PtOIDS4rgV+AjxEuN4hmd2O0d2XARcQTu6rgM8JjZk1qayjf97dP01Y/gPCSXoD8Jso5nRieCr6DM8Tqk2er7bKvwM3mtkG4DqiX9fRtpsIbSJ/iXriHFpt32uBEwmlprXAVcCJ1eKuM3f/inDiP55w3G8Hznb35dEqZwFlURXZFMLfE0Jj+LPARuCvwO3u/kJ9YpG6M7XLSGNkZg8By9099hKJSFOnEoE0CmY2zMy+ZmbNou6VJxPqmkWknnRlsTQW3YFHCQ23K4Gp7v5adkMSaRpUNSQikudUNSQikucaXdVQ165dvbCwMNthiIg0KgsXLvzU3bsle63RJYLCwkJKS0uzHYaISKNiZtWvKN9BVUMiInlOiUBEJM8pEYiI5LlG10YgIpm3detWVq5cyZdffln7ypJVrVu3plevXrRs2TLtbZQIRKRWK1eupH379hQWFpL6vkKSbe7O2rVrWblyJX379k17u7yoGiopgcJCaNYsPJboNt4idfLll1/SpUsXJYEcZ2Z06dKlziW3Jl8iKCmByZNhU3RLkxUrwnOACRNSbyciO1MSaBx25+/U5EsE06ZVJYFKmzaF5SIikgeJ4MMP67ZcRHLP2rVrKSoqoqioiO7du9OzZ88dz7/66qsaty0tLeXiiy+u9T0OP/zwBon1xRdf5MQTT2yQfWVKk08Evavf5K+W5SJSfw3dLtelSxcWL17M4sWLmTJlCpdddtmO561ataKioiLltsXFxcyYMaPW91iwYEH9gmzEmnwimD4d2rbdeVnbtmG5iDS8yna5FSvAvapdrqE7aUyaNIkpU6YwYsQIrrrqKv7+979z2GGHMXjwYA4//HDefvttYOdf6DfccAPnnHMOo0ePpl+/fjsliIKCgh3rjx49mnHjxnHggQcyYcIEKkdpnjt3LgceeCBDhw7l4osvrvWX/2effcYpp5zCIYccwqGHHsqSJUsAeOmll3aUaAYPHsyGDRtYtWoVo0aNoqioiK9//evMnz+/YQ9YDZp8Y3Flg/C0aaE6qHfvkATUUCwSj5ra5Rr6/27lypUsWLCA5s2bU15ezvz582nRogXPPvss1157LY888sgu2yxfvpwXXniBDRs20L9/f6ZOnbpLn/vXXnuNZcuWsc8++zBy5Ej+8pe/UFxczPnnn8+8efPo27cv48ePrzW+66+/nsGDBzNnzhyef/55zj77bBYvXszNN9/MbbfdxsiRI9m4cSOtW7dm5syZfOtb32LatGls27aNTdUPYoyafCKA8OXTiV8kMzLZLved73yH5s2bA7B+/XomTpzIO++8g5mxdevWpNuccMIJ7LHHHuyxxx7stdderF69ml69eu20zvDhw3csKyoqoqysjIKCAvr167ejf/748eOZOXNmjfG9/PLLO5LRMcccw9q1aykvL2fkyJFcfvnlTJgwgbFjx9KrVy+GDRvGOeecw9atWznllFMoKiqq17GpiyZfNSQimZXJdrl27drtmP/Rj37E0UcfzdKlS3n88cdT9qXfY489dsw3b948aftCOuvUxzXXXMNdd93F5s2bGTlyJMuXL2fUqFHMmzePnj17MmnSJO6///4Gfc+axJYIzGxfM3vBzN40s2VmdkmSdUab2XozWxxN18UVj4hkRrba5davX0/Pnj0BuPfeext8//379+f999+nrKwMgIceeqjWbY488khKosaRF198ka5du9KhQwfee+89Bg4cyNVXX82wYcNYvnw5K1asYO+99+a8887j3HPPZdGiRQ3+GVKJs2qoArjC3ReZWXtgoZn92d3frLbefHdvXH2tRCSlbLXLXXXVVUycOJGf/OQnnHDCCQ2+/zZt2nD77bdz3HHH0a5dO4YNG1brNpWN04cccght27blvvvuA+CWW27hhRdeoFmzZgwYMIDjjz+e2bNn8/Of/5yWLVtSUFCQ0RJBxu5ZbGZ/BG519z8nLBsN/KAuiaC4uNh1YxqRzHrrrbc46KCDsh1G1m3cuJGCggLcnQsuuID999+fyy67LNth7SLZ38vMFrp7cbL1M9JGYGaFwGDglSQvH2Zmr5vZU2Y2IMX2k82s1MxK16xZE2OkIiKp/eY3v6GoqIgBAwawfv16zj///GyH1CBiLxGYWQHwEjDd3R+t9loHYLu7bzSzMcD/uvv+Ne1PJQKRzFOJoHHJqRKBmbUEHgFKqicBAHcvd/eN0fxcoKWZdY0zJhER2VmcvYYMuBt4y91/mWKd7tF6mNnwKJ61ccUkIiK7irPX0EjgLOANM1scLbsW6A3g7ncC44CpZlYBbAbO9Ey1XouICBBjInD3l4EaB8Z291uBW+OKQUREaqcri0Uk5x199NE8/fTTOy275ZZbmDp1asptRo8eTWXHkjFjxrBu3bpd1rnhhhu4+eaba3zvOXPm8OabVZc/XXfddTz77LN1CT+pXBquWolARHLe+PHjmT179k7LZs+endbAbxBGDe3UqdNuvXf1RHDjjTfyjW98Y7f2lauUCEQk540bN44nn3xyx01oysrK+Ne//sWRRx7J1KlTKS4uZsCAAVx//fVJty8sLOTTTz8FYPr06RxwwAEcccQRO4aqhnCNwLBhwxg0aBCnnXYamzZtYsGCBTz22GNceeWVFBUV8d577zFp0iQefvhhAJ577jkGDx7MwIEDOeecc9iyZcuO97v++usZMmQIAwcOZPny5TV+vmwPV50Xo4+KSMO59FJYvLj29eqiqAhuuSX16507d2b48OE89dRTnHzyycyePZvTTz8dM2P69Ol07tyZbdu2ceyxx7JkyRIOOeSQpPtZuHAhs2fPZvHixVRUVDBkyBCGDh0KwNixYznvvPMA+OEPf8jdd9/NRRddxEknncSJJ57IuHHjdtrXl19+yaRJk3juuec44IADOPvss7njjju49NJLAejatSuLFi3i9ttv5+abb+auu+5K+fmyPVy1SgQi0igkVg8lVgv9/ve/Z8iQIQwePJhly5btVI1T3fz58zn11FNp27YtHTp04KSTTtrx2tKlSznyyCMZOHAgJSUlLFu2rMZ43n77bfr27csBBxwAwMSJE5k3b96O18eOHQvA0KFDdwxUl8rLL7/MWWedBSQfrnrGjBmsW7eOFi1aMGzYMGbNmsUNN9zAG2+8Qfv27WvcdzpUIhCROqnpl3ucTj75ZC677DIWLVrEpk2bGDp0KB988AE333wzr776KnvuuSeTJk1KOfx0bSZNmsScOXMYNGgQ9957Ly+++GK94q0cyro+w1hfc801nHDCCcydO5eRI0fy9NNP7xiu+sknn2TSpElcfvnlnH322fWKVSUCEWkUCgoKOProoznnnHN2lAbKy8tp164dHTt2ZPXq1Tz11FM17mPUqFHMmTOHzZs3s2HDBh5//PEdr23YsIEePXqwdevWHUNHA7Rv354NGzbssq/+/ftTVlbGu+++C8ADDzzAUUcdtVufLdvDVatEICKNxvjx4zn11FN3VBENGjSIwYMHc+CBB7LvvvsycuTIGrcfMmQIZ5xxBoMGDWKvvfbaaSjpH//4x4wYMYJu3boxYsSIHSf/M888k/POO48ZM2bsaCQGaN26NbNmzeI73/kOFRUVDBs2jClTpuzW58r2cNUZG4a6oWjQOZHM06BzjUtODTonIiK5T4lARCTPKRGISFoaWzVyvtqdv5MSgYjUqnXr1qxdu1bJIMe5O2vXrqV169Z12k69hkSkVr169WLlypXoVrG5r3Xr1vTq1atO2ygRiEitWrZsSd++fbMdhsREVUMiInlOiUBEJM8pEYiI5DklAhGRPKdEICKS55QIRETynBKBiEieUyIQEclzSgQiInlOiUBEJM8pEYiI5DklAhGRPKdEICKS55QIRETynBKBiEieUyIQEclzsSUCM9vXzF4wszfNbJmZXZJkHTOzGWb2rpktMbMhccUjIiLJxXmHsgrgCndfZGbtgYVm9md3fzNhneOB/aNpBHBH9CgiIhkSW4nA3Ve5+6JofgPwFtCz2monA/d78Degk5n1iCsmERHZVUbaCMysEBgMvFLtpZ7APxOer2TXZIGZTTazUjMr1c2zRUQaVuyJwMwKgEeAS929fHf24e4z3b3Y3Yu7devWsAGKiOS5WBOBmbUkJIESd380ySofAfsmPO8VLRMRkQyJs9eQAXcDb7n7L1Os9hhwdtR76FBgvbuviismERHZVZy9hkYCZwFvmNniaNm1QG8Ad78TmAuMAd4FNgHfizEeERFJIrZE4O4vA1bLOg5cEFcMIiJSO11ZLCKS55QIRETynBKBiEieUyIQEclzSgQiInlOiUBEJM8pEYiI5DklAhGRPKdEICKS55QIRETynBKBiEieUyIQEclzSgQiInlOiUBEJM8pEYiI5Lm8SQTusGBBtqMQEck9eZMI7rkHRo6EV17JdiQiIrklbxLBGWdAly5w443ZjkREJLfkTSIoKIArroC5c+HVV7MdjYhI7sibRABw4YXQuTP8+MfZjkREJHfkVSJo3x4uuwwefxxeey3b0YiI5Ia8SgQAF10EnTqprUBEpFLeJYKOHeHSS2HOHHj99WxHIyKSfXmXCAAuvhg6dFBbgYgI5Gki2HNPuOQSeOQRWLo029GIiGRXXiYCCNVD7durVCAikreJoHPn0HD8hz/Am29mOxoRkezJ20QAoStp27YwfXq2IxERyZ68TgRdu8IFF8Ds2fD229mORkQkO/I6EUAYdqJ1a5UKRCR/xZYIzOweM/vEzJL2yzGz0Wa23swWR9N1ccVSk732gqlToaQE3nknGxGIiGRXnCWCe4HjallnvrsXRVPWrvW98kpo1Qr+67+yFYGISPbElgjcfR7wWVz7b0h77w1TpsADD8B772U7GhGRzMp2G8FhZva6mT1lZgNSrWRmk82s1MxK16xZE0sgV14JLVrAf/93LLsXEclZ2UwEi4A+7j4I+BUwJ9WK7j7T3Yvdvbhbt26xBLPPPjB5Mtx3H5SVxfIWIiI5KWuJwN3L3X1jND8XaGlmXbMVD8BVV0GzZioViEh+SSsRmFk7M2sWzR9gZieZWcv6vLGZdTczi+aHR7Gsrc8+66tXLzj3XJg1Cz78MJuRiIhkTrolgnlAazPrCTwDnEXoFZSSmT0I/BXob2Yrzez7ZjbFzKZEq4wDlprZ68AM4Ex39935EA3p6qvD409/WrWspAQKC0NpobAwPBcRaSosnXOvmS1y9yFmdhHQxt1vMrPF7l4Uf4g7Ky4u9tLS0ljf4/zz4d57Qw+il14KbQebNlW93rYtzJwJEybEGoaISIMxs4XuXpzstXRLBGZmhwETgCejZc0bIrhc9B//Adu3w003wbRpOycBCM+nTctObCIiDa1FmutdCvwH8H/uvszM+gEvxBdWdhUWwsSJ4Vf/li3J11Ebgog0FWmVCNz9JXc/yd1/FjUaf+ruF8ccW1Zdey1UVIR7FiTTu3dm4xERiUu6vYZ+Z2YdzKwdsBR408yujDe07OrXD846C778Etq02fk1DV0tIk1Jum0EB7t7OXAK8BTQl9BzqEmbNg22bYOjj4Y+fcAsPKqhWESaknTbCFpG1w2cAtzq7lvNLOtdPeO2337hhP/ww+Fq4732ynZEIiINL90Swa+BMqAdMM/M+gDlcQWVS6ZNCw3Gv/hFtiMREYlHuo3FM9y9p7uP8WAFcHTMseWE/v3hzDPhttvg00+zHY2ISMNLt7G4o5n9snIEUDP7BaF0kBd++MNw7cAvf5ntSEREGl66VUP3ABuA06OpHJgVV1C55qCD4PTT4Ve/gvffz3Y0IiINK91E8DV3v97d34+m/wT6xRlYrvnP/wx3MTv8cHjttWxHIyLScNJNBJvN7IjKJ2Y2EtgcT0i5qX9/ePll2GMPOOooePbZbEckItIw0k0EU4DbzKzMzMqAW4HzY4sqRx10ECxYEIagGDMGHnww2xGJiNRfur2GXo/uJHYIcIi7DwaOiTWyHNWzJ8ybF6qIvvtdNSCLSONXpzuURXcVq7x+4PIY4mkUOnWCP/0Jxo2DK66AH/wgjFYqItIY1edWldZgUTRCrVvD7NlwwQXhYrOzzoKvvsp2VCIidZfuEBPJNPkhJmrTvHnoUtqzZxit9JNP4NFHU49YKiKSi2pMBGa2geQnfAPaJFmed8zCjWx69Aj3Ox49GubOhb33znZkIiLpqbFqyN3bu3uHJFN7d69PaaLJmTQJHn8cli8PDcnvvJPtiERE0lOfNgKp5vjj4YUXoLwcRo6EV1/NdkQiIrVTImhgw4fDX/4C7dqF+xj86U/ZjkhEpGZKBDE44AD4619h//3h29+GBx7IdkQiIqkpEcSke3d46aUwHMXZZ8NNN4HnfT8rEclFSgQx6tAh9CAaPx6uvhouuQS++CLbUYmI7EyJIGatWsFvfwuXX151zcFll8E//pHtyEREAvNGVl9RXFzspaWl2Q5jt7z8Mtx+e7gH8tat8I1vhCuTTzwRWqgzrkiTtHkzrF4dJvcwgnGrVuGxckp83iymn+dmttDdi5O9ptNPBpSUhHsff/gh9O4N//M/sG4d3HknnHoq9OoF558P552nC9FEGoOtW2HNGvj4452n1at3XVZex7u7t2iROlGce26oYm5oSgQxKymByZPDrS4BVqyAq66CmTPhgw/giSdCKeFHP4Ibb4TTToN//3c44ohw1bKIxGPbtnCSXrcO1q/f+THV/CefhJN7qvuXd+gQOop07w6DBsG3vlX1fK+9wrA0X30FW7ZUTbU9T1y2557xHAtVDcWssDCc/Kvr0wfKyqqe/+MfcMcdMGtW+NINHBgSwv/7f1BQkKloRZqetWvDGGCPPgorV1ad1DdsqH3bggLo2DGMONyxYziZV57Y9967ar7yeZscHninpqohJYKYNWuWvNuoWfKhq7/4Ioxqettt4ZaY7dvDxIkwdSocfHD88Yo0BeXl8Mc/hv+lZ56BiopwXc+AAVUn9U6dap7v0KFptd0pEWRRuiWC6tzhlVdCtdFDD4Wi4ejRoR1h7NgwDLaIVNm0CZ58Mpz8n3wyVKX07g1nnhmmoqL8rm6tKRHE1n3UzO4xs0/MbGmK183MZpjZu2a2xMyGxBVLNk2fDm3b7rysbduwvCZmcOihcP/9oTj705+GhDJhQhjp9MILQ4lBpDHYsCEMvfLGG+lVyaRry5Yw2OOECaHa5vTTw+1kzz8/PH7wAfzsZzB4cH4ngdrEViIws1HARuB+d/96ktfHABcBY4ARwP+6+4ja9tvYSgSwa6+h6dPDF7eutm8Pg9rdfXeo79yyJXzBv//9cNvMuBqSROqiogKWLQsl2srpzTd3riLt3DmUlhOnvn3DY58+Nd/To6Ii/B/Mnh3+D9atC/sbNy788h81KjTKys6yVjVkZoXAEykSwa+BF939wej528Bod19V0z4bYyKIw+efhwRz992weHGoKho7NiSF0aPj64ssksg9lFgTT/oLF1b1kuvcGUaMCNOQIaFPfVnZrtPmzTvvt0uXXRNF9+4hAfzhD6HrZvv2cMop4eT/zW9Cy5YZ+9iNUq4mgieAn7r7y9Hz54Cr3X2Xs7yZTQYmA/Tu3XvoimSV7nls0aKQEEpKQo+Ifv3ge98L90jo1Svb0UlTUl4OpaVVJ/2//x1WRT/dWrUKJdTKE//w4fC1r9VeJeMeumUmSxAffBAet2wJ67ZuHQZyPPPMMOx7LvfSyTWNPhEkUokgtc2bQ1H57rvDL6dmzeC440Ip4cQTwz+q5I81a0Jp8bXXwuPSpVUn1N2xdWs4KVeeMvbfv+qkP2IEHHJIuOipoW3fHhLFypXQv79uBbu7cvXK4o+AfROe94qWyW5q0ya0PUyYAO+9F65JmDUrXKTWrRucdRaccEK4g5p6HTUd27eHX86VJ/zKk/+//lW1Tu/e4dqU+pxEzUIpc8QIGDYsVPtkQrNmVX31JR7ZLBGcAFxIVWPxDHcfXts+VSKom4oKePppuOceeOyx8Lx163AHtWOPDdPQoWpcayy2bAkNsYkn/Ndfr+qJ07w5HHRQ6Co5eHB4HDQo1LlLfstK1ZCZPQiMBroCq4HrgZYA7n6nmRlwK3AcsAn4Xm3VQqBEUB8bNsC8efDcc2FasiQs79gxNDBXJoaDDmoaXe3cw72j580L02uvhUbHoUOrpn32yV5827aFHi+ffRYa/z//vOb5Tz8NV6BXVITtCwrCSb6oqOrEP2CASnuSnC4ok6Q++SS0JVQmhvffD8t79IBjjqlKDL17ZzfOdG3fHn4tv/RS1cl/9erwWrduUFwc6riXL6+q5+7RY+fE0BDJwT3Uz3/wQZjefz88rlgRTuaVJ/f162veT7t2oUvwnnuGapjOnat+7RcVhYZY9Q6TdCkRSFo++KAqKTz/fEgUAPvtFxLC6NHhxNmxY7j8vvIxW932KirCr/zKk/78+eEEC6G31FFHhT7lo0aFRsbKUs7GjaFaZeHCqumtt6qSQ/fuIWnUlBzKy6tO9Mmmyu6TlfbaK5RGunULJ/TKk3viib76vBr3pSEpEUiduYdeJpWJ4aWXUl8R2qZNSAqJCaL6fMeOoaGydeuqYXUrh9ZNd76iAl59teoX/4IF4aQOoQdL5Ul/1KhwUVJdqreSJYfly6vGg+rePTS2fv55ONGvXbvz9u3bhwuiEqd+/aoukmrXrs5/ApEGpUQg9VZ5tejataFKo7w8PFZONT2vPFk3pIEDq076Rx4ZSioN7YsvQnIoLQ2JYdky6No1+cm+c+em0a4iTVeudh+VRqRFi9AwuTu2bQulifLyncdW/+qrneeTLUuc3749NIgecURmesG0axd6V40cGf97iWSTEkEj0FBjFWVL8+ZVQ/uKSO5RIshxye5wNnlymG9MyUBEcpc6n+W4adN27YGyaVNYLiLSEJQIctyHH9ZtuYhIXSkR5LhUF3M1lou8RCT3KRHkuN29w5mISLqUCHLchAkwc2bVBVJ9+oTnaigWkYaiXkONQOXQ0iIicVCJQEQkzykRiIjkOSUCEZE8p0QgIpLnlAhERPKcEkEeKCkJY1hmqAUAAAsQSURBVOI3axYeS0qyHZGI5BJ1H23iNGidiNRGJYImToPWiUhtlAiaOA1aJyK1USJo4jRonYjURomgidOgdSJSGyWCJk6D1olIbdRrKA9o0DoRqYlKBCIieU6JQEQkzykRiIjkOSUCSYuGqRBputRYLLXSMBUiTVusJQIzO87M3jazd83smiSvTzKzNWa2OJrOjTMe2T0apkKkaYutRGBmzYHbgG8CK4FXzewxd3+z2qoPufuFccUh9adhKkSatjhLBMOBd939fXf/CpgNnBzj+0lMNEyFSNMWZyLoCfwz4fnKaFl1p5nZEjN72Mz2TbYjM5tsZqVmVrpmzZo4YpUaaJgKkaYt272GHgcK3f0Q4M/AfclWcveZ7l7s7sXdunXLaICiYSpEmro4ew19BCT+wu8VLdvB3dcmPL0LuCnGeKQeNEyFSNMVZ4ngVWB/M+trZq2AM4HHElcwsx4JT08C3ooxHskiXYcgkrtiKxG4e4WZXQg8DTQH7nH3ZWZ2I1Dq7o8BF5vZSUAF8BkwKa54JHt0HYJIbjN3z3YMdVJcXOylpaXZDkPqoLAwnPyr69MHysoyHY1IfjKzhe5enOy1bDcWSx7QdQgiuU2JQGKn6xBEcpsSgcRO1yGI5DYlAoldQ1yHoF5HIvHR6KOSEfW5DkG9jkTipRKB5DyNfioSLyUCyXnqdSQSLyUCyXnqdSQSLyUCyXkN0etIjc0iqSkRSM6rb6+jysbmFSvAvaqxWclAJNAQE9LkaYgLEQ0xIXmuIRqbVbUkTZkSgTR59W1sVtWSNHVKBNLk1bexWdcxSFOnRCBNXn0bm1W1JE2dhpiQvFCfIS56907e2FzXqiUNkSG5SiUCkVrkQtWSShQSJyUCkVpku2pJjdUSNyUCkTRMmBCuOdi+PTzWpUqnvr2WVKKQuCkRiMSsvlVLuVCiUCJp2pQIRGJW36qlbJcociGRKBHFzN0b1TR06FAXySe//a1727bu4TQcprZtw/J0mO28beVklt72ffok375Pn8zEX9/tK/fRp0/4zH361G3bhtg+FwClnuK8mvUTe10nJQLJR/U5EdX3RJ7tRKJE1DCJSIlAJI/V90SW7USiRFT/RORecyJQG4FIE1ffNor6NnbXt42jvtvXt7G9vtvXt40mE0OcKBGI5IH6dH/NdiJRIqrf9ulQIhCRWmUzkSgR1W/7tKSqM8rVSW0EIlJX2WysbQxtBLpDmYhIzEpKQp3+hx+GX/LTp9etVFXf7aHmO5QpEYiI5AHdqlJERFKKNRGY2XFm9raZvWtm1yR5fQ8zeyh6/RUzK4wzHhER2VVsicDMmgO3AccDBwPjzezgaqt9H/jc3fcD/gf4WVzxiIhIcnGWCIYD77r7++7+FTAbOLnaOicD90XzDwPHmpnFGJOIiFQTZyLoCfwz4fnKaFnSddy9AlgPdKm+IzObbGalZla6Zs2amMIVEclPjeKexe4+E5gJYGZrzCzJHWRzQlfg02wHUYNcjw9yP0bFVz+Kr37qE1+fVC/EmQg+AvZNeN4rWpZsnZVm1gLoCKytaafu3q0hg2xIZlaaqntWLsj1+CD3Y1R89aP46ieu+OKsGnoV2N/M+ppZK+BM4LFq6zwGTIzmxwHPe2O7sEFEpJGLrUTg7hVmdiHwNNAcuMfdl5nZjYRLnR8D7gYeMLN3gc8IyUJERDIo1jYCd58LzK227LqE+S+B78QZQ4bNzHYAtcj1+CD3Y1R89aP46ieW+BrdEBMiItKwNMSEiEieUyIQEclzSgR1ZGb7mtkLZvammS0zs0uSrDPazNab2eJoui7ZvmKMsczM3ojee5ehWi2YEY3xtMTMhmQwtv4Jx2WxmZWb2aXV1sn48TOze8zsEzNbmrCss5n92czeiR73TLHtxGidd8xsYrJ1Yorv52a2PPob/p+ZdUqxbY3fhxjju8HMPkr4O45JsW2NY5LFGN9DCbGVmdniFNvGevxSnVMy+v1LdaMCTcknoAcwJJpvD/wDOLjaOqOBJ7IYYxnQtYbXxwBPAQYcCrySpTibAx8DfbJ9/IBRwBBgacKym4BrovlrgJ8l2a4z8H70uGc0v2eG4vs3oEU0/7Nk8aXzfYgxvhuAH6TxHXgP6Ae0Al6v/v8UV3zVXv8FcF02jl+qc0omv38qEdSRu69y90XR/AbgLXYdOiPXnQzc78HfgE5m1iMLcRwLvOfuWb9S3N3nEbowJ0ocC+s+4JQkm34L+LO7f+bunwN/Bo7LRHzu/oyHoVkA/ka4aDMrUhy/dKQzJlm91RRfNL7Z6cCDDf2+6ajhnJKx758SQT1Ew2YPBl5J8vJhZva6mT1lZgMyGhg48IyZLTSzyUleT2ccqEw4k9T/fNk8fpX2dvdV0fzHwN5J1smVY3kOoZSXTG3fhzhdGFVd3ZOiaiMXjt+RwGp3fyfF6xk7ftXOKRn7/ikR7CYzKwAeAS519/JqLy8iVHcMAn4FzMlweEe4+xDCEOAXmNmoDL9/raKrzU8C/pDk5Wwfv114KIfnZF9rM5sGVAAlKVbJ1vfhDuBrQBGwilD9kovGU3NpICPHr6ZzStzfPyWC3WBmLQl/sBJ3f7T66+5e7u4bo/m5QEsz65qp+Nz9o+jxE+D/CMXvROmMAxW344FF7r66+gvZPn4JVldWmUWPnyRZJ6vH0swmAScCE6KTxS7S+D7Ewt1Xu/s2d98O/CbF+2b7+LUAxgIPpVonE8cvxTklY98/JYI6iuoT7wbecvdfpline7QeZjaccJxrHEyvAeNrZ2btK+cJDYpLq632GHB21HvoUGB9QhE0U1L+Csvm8asmcSysicAfk6zzNPBvZrZnVPXxb9Gy2JnZccBVwEnuvinFOul8H+KKL7Hd6dQU75vOmGRx+gaw3N1XJnsxE8evhnNK5r5/cbWEN9UJOIJQRFsCLI6mMcAUYEq0zoXAMkIPiL8Bh2cwvn7R+74exTAtWp4YnxHuHvce8AZQnOFj2I5wYu+YsCyrx4+QlFYBWwn1rN8n3BvjOeAd4Fmgc7RuMXBXwrbnAO9G0/cyGN+7hPrhyu/hndG6+wBza/o+ZCi+B6Lv1xLCSa1H9fii52MIPWXey2R80fJ7K793Cetm9PjVcE7J2PdPQ0yIiOQ5VQ2JiOQ5JQIRkTynRCAikueUCERE8pwSgYhInlMiEImY2TbbeWTUBhsJ08wKE0e+FMklsd6qUqSR2ezuRdkOQiTTVCIQqUU0Hv1N0Zj0fzez/aLlhWb2fDSo2nNm1jtavreF+wO8Hk2HR7tqbma/icacf8bM2kTrXxyNRb/EzGZn6WNKHlMiEKnSplrV0BkJr61394HArcAt0bJfAfe5+yGEAd9mRMtnAC95GDRvCOGKVID9gdvcfQCwDjgtWn4NMDjaz5S4PpxIKrqyWCRiZhvdvSDJ8jLgGHd/Pxoc7GN372JmnxKGTdgaLV/l7l3NbA3Qy923JOyjkDBu/P7R86uBlu7+EzP7E7CRMMrqHI8G3BPJFJUIRNLjKebrYkvC/Daq2uhOIIz9NAR4NRoRUyRjlAhE0nNGwuNfo/kFhNEyASYA86P554CpAGbW3Mw6ptqpmTUD9nX3F4CrgY7ALqUSkTjpl4dIlTa28w3M/+TulV1I9zSzJYRf9eOjZRcBs8zsSmAN8L1o+SXATDP7PuGX/1TCyJfJNAd+GyULA2a4+7oG+0QiaVAbgUgtojaCYnf/NNuxiMRBVUMiInlOJQIRkTynEoGISJ5TIhARyXNKBCIieU6JQEQkzykRiIjkuf8PPtvG3dq1hy0AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_VJCu_M8FNrY"
      },
      "outputs": [],
      "source": [
        "# Listing 4.20 Plotting the training and validation accuracy\n",
        "def plot_acc(historyDic):\n",
        "  history_dict = historyDic.history\n",
        "  acc = history_dict[\"accuracy\"]\n",
        "  val_acc = history_dict[\"val_accuracy\"]\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  plt.clf()\n",
        "  plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "  plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "  plt.title(\"Training and validation accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Da6yae69FNn6",
        "outputId": "0bc31508-bbc6-4a57-d3c5-6c06e467ee3c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_acc(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FcFGyXuFsJT"
      },
      "source": [
        "- The model begins to overfit after nine epochs.\n",
        "- train a new model from scratch for nine epochs and then evaluate it on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qa4mRCCFNk9",
        "outputId": "58a826a8-ebd6-4cc5-ae19-1210e7a7da97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "18/18 [==============================] - 1s 15ms/step - loss: 2.5081 - accuracy: 0.5423\n",
            "Epoch 2/9\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 1.3681 - accuracy: 0.7105\n",
            "Epoch 3/9\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 1.0345 - accuracy: 0.7752\n",
            "Epoch 4/9\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.8243 - accuracy: 0.8213\n",
            "Epoch 5/9\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.6578 - accuracy: 0.8626\n",
            "Epoch 6/9\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.5254 - accuracy: 0.8923\n",
            "Epoch 7/9\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4219 - accuracy: 0.9116\n",
            "Epoch 8/9\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3459 - accuracy: 0.9286\n",
            "Epoch 9/9\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.2821 - accuracy: 0.9360\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb681adfc50>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Listing 4.21 Retraining a model from scratch\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=9,\n",
        "    batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AC6z11QF06x",
        "outputId": "d9f3c992-c2e0-4598-9a5f-619ccd35c756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 4ms/step - loss: 1.0029 - accuracy: 0.7760\n"
          ]
        }
      ],
      "source": [
        "# evaluate on test data\n",
        "results = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5-s-SdQGUJf",
        "outputId": "d4b40404-555b-45b8-90ba-20fdb88bdd62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1.0028505325317383, 0.7760462760925293]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhD_VBCMEn5u"
      },
      "source": [
        "- accuracy of ~80%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMJ_ofvLGtru"
      },
      "source": [
        "- With a balanced binary classification problem, the accuracy reached by a purely random classifier would be 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqYTybRZHBhk",
        "outputId": "7ab4844a-fd86-4a45-9365-7f034d09476c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1709706144256456"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# accuracy of a random baseline\n",
        "import copy\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
        "hits_array.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiXVGrLGHZhk"
      },
      "source": [
        "- a random classifier would score around 18% classification accuracy, so the results of our model seem pretty good in that light."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bon7U4e3H6BF"
      },
      "source": [
        "### 4.2.5 Generating predictions on new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM0pVqvaM1W7"
      },
      "source": [
        "- predict method on new samples returns a class probability distribution over all 46 topics for each sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1t4YAbnHUx7",
        "outputId": "aa3f1e35-0ea6-403b-9f7f-b96c5569d157"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.8837530e-05, 6.7533160e-06, 5.1271923e-06, ..., 9.5539053e-06,\n",
              "        1.3200440e-07, 6.1318860e-07],\n",
              "       [1.6358773e-03, 1.7279527e-01, 1.1123266e-01, ..., 2.2680401e-06,\n",
              "        8.8490953e-05, 4.2466022e-04],\n",
              "       [2.8255391e-03, 7.9416132e-01, 1.2722441e-02, ..., 2.1047473e-03,\n",
              "        7.0827390e-04, 3.0647749e-03],\n",
              "       ...,\n",
              "       [1.4435100e-05, 4.5932702e-05, 2.8841935e-06, ..., 9.6404028e-06,\n",
              "        5.1958204e-07, 1.9370395e-06],\n",
              "       [1.4782562e-03, 2.6288005e-02, 9.7392139e-04, ..., 2.2092291e-04,\n",
              "        7.3542469e-05, 1.1169551e-04],\n",
              "       [1.1032686e-03, 7.6561064e-01, 1.8683610e-02, ..., 9.5868262e-04,\n",
              "        3.3863942e-04, 3.6141591e-04]], dtype=float32)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predictions\n",
        "predictions = model.predict(x_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOMl3BkjNSGT",
        "outputId": "83cc26bd-e826-41a0-849b-c60c88bec14e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape of prediction\n",
        "predictions[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnrY89npNZDy",
        "outputId": "52542b01-d69d-4931-9290-72f8f3297bbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sum of all probabilites of a sample\n",
        "np.sum(predictions[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CaB2uJENh_j",
        "outputId": "d3a07148-54ad-4ef7-f234-871ec86f6667"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# label of 986th sample in x_test\n",
        "y_test[985]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG_mjk48N8TO"
      },
      "source": [
        "- as it is one hot-in-coded form\n",
        "  - value = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-28J-IFPN7gU",
        "outputId": "b234b809-7e08-4740-f82f-9ca3a8a2157c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.5432404e-05, 7.6285251e-05, 7.3129318e-06, 9.9719101e-01,\n",
              "       9.3938690e-04, 2.0659130e-05, 4.5863380e-06, 3.3718239e-05,\n",
              "       7.9132187e-05, 1.9290672e-05, 2.4386416e-05, 1.3100541e-04,\n",
              "       6.9260335e-05, 3.7085804e-06, 4.9731748e-06, 5.2494893e-06,\n",
              "       1.6153776e-04, 1.0686213e-04, 3.9231261e-05, 1.1510526e-04,\n",
              "       2.1547827e-04, 3.1600106e-05, 3.1376716e-05, 1.6012229e-05,\n",
              "       3.8682490e-05, 9.5070473e-06, 1.9021450e-05, 8.4452258e-06,\n",
              "       2.0605061e-05, 2.9959552e-05, 1.5959368e-04, 3.2121497e-05,\n",
              "       2.8621374e-05, 6.0132857e-06, 8.4859166e-06, 6.0757524e-05,\n",
              "       2.9216515e-05, 1.3562959e-06, 9.8718279e-05, 4.3551998e-05,\n",
              "       1.6476582e-05, 3.5964988e-06, 3.6066278e-06, 2.5922292e-05,\n",
              "       8.4274416e-07, 2.3809228e-06], dtype=float32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prediction of the 986th sample\n",
        "predictions[985]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGXjEKy_OR0w",
        "outputId": "7331e5d7-d401-47f2-e383-ac3b3fd8a7af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.997191"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# max probability of the 986th sample\n",
        "np.max(predictions[985])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSCmL251OXbl",
        "outputId": "35680e2a-664e-45cb-8356-ce08553b8ca8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# index of the max probability\n",
        "np.argmax(predictions[985])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rwatf3dOdLC"
      },
      "source": [
        "- from predictions and available data predection is correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oXqPudNOmlR"
      },
      "source": [
        "### 4.2.6 A different way to handle the labels and the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl3YEGg2OpMy"
      },
      "source": [
        "- labels can be casted as follows\n",
        "```\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "```\n",
        "- when labels are in integer form we can use `sparse_categorical_crossentropy`\n",
        "```\n",
        "model.compile(\n",
        "  optimizer=\"rmsprop\",\n",
        "  loss=\"sparse_categorical_crossentropy\",\n",
        "  metrics=[\"accuracy\"])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZC_W0oTPCz5"
      },
      "source": [
        "### 4.2.7 The importance of having sufficiently large intermediate layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbvQQWH9PMSv",
        "outputId": "40bfa63e-6342-4e2c-fa3a-3d7b8b15e62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 2.6370 - accuracy: 0.4121 - val_loss: 1.8691 - val_accuracy: 0.5680\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1.5855 - accuracy: 0.5897 - val_loss: 1.5336 - val_accuracy: 0.5880\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1.3121 - accuracy: 0.6324 - val_loss: 1.4459 - val_accuracy: 0.6350\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1.1506 - accuracy: 0.7098 - val_loss: 1.4081 - val_accuracy: 0.6660\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 1.0254 - accuracy: 0.7457 - val_loss: 1.3840 - val_accuracy: 0.6850\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.9271 - accuracy: 0.7608 - val_loss: 1.3953 - val_accuracy: 0.6820\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.8474 - accuracy: 0.7730 - val_loss: 1.4139 - val_accuracy: 0.6980\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.7829 - accuracy: 0.7866 - val_loss: 1.4095 - val_accuracy: 0.7020\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7259 - accuracy: 0.8058 - val_loss: 1.4443 - val_accuracy: 0.7000\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6793 - accuracy: 0.8175 - val_loss: 1.4817 - val_accuracy: 0.7040\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.6400 - accuracy: 0.8222 - val_loss: 1.5126 - val_accuracy: 0.6960\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.6030 - accuracy: 0.8307 - val_loss: 1.5691 - val_accuracy: 0.6990\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5713 - accuracy: 0.8398 - val_loss: 1.6020 - val_accuracy: 0.6990\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.5417 - accuracy: 0.8504 - val_loss: 1.6552 - val_accuracy: 0.7000\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5134 - accuracy: 0.8587 - val_loss: 1.7167 - val_accuracy: 0.6930\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4918 - accuracy: 0.8647 - val_loss: 1.7809 - val_accuracy: 0.6910\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.8680 - val_loss: 1.8462 - val_accuracy: 0.6870\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.8750 - val_loss: 1.9570 - val_accuracy: 0.6880\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.8775 - val_loss: 1.9655 - val_accuracy: 0.6890\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8810 - val_loss: 2.0515 - val_accuracy: 0.6960\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6825ed950>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Listing 4.22 A model with an information bottleneck\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6Xwm6QWPhXP"
      },
      "source": [
        "|    Description    |tra_acc|val_acc|tra_loss|val_loss|\n",
        "|-------------------|-------|-------|--------|--------|\n",
        "|with out bottleneck|0.95   |0.79    |0.11   |1.0     |\n",
        "|with bottleneck    |0.88   |0.69    |0.41   |2.05    |\n",
        "|difference         |-0.07  |-0.10   |-0.30  |-1.05   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrcFtd8xSejU"
      },
      "source": [
        "- there is a drop of 10% in accuracy\n",
        "- This drop is mostly due to the fact that we’re trying to compress a lot of information into an intermediate space that is too low-dimensional.\n",
        "- The model is able to cram most of the necessary information into these four-dimensional representations, but not all of it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-gmEcLDTcWR"
      },
      "source": [
        "### 4.2.8 Further experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yzp5SDjTdTC"
      },
      "source": [
        "#### Try using smaller layers: 32 units"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbJsOi28Tq0S",
        "outputId": "151a0bdc-c217-45a3-bae9-386f3b6e8515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 2.1585 - accuracy: 0.5913 - val_loss: 1.4656 - val_accuracy: 0.6770\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 1.2254 - accuracy: 0.7241 - val_loss: 1.2092 - val_accuracy: 0.7300\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.9300 - accuracy: 0.7904 - val_loss: 1.0890 - val_accuracy: 0.7600\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7178 - accuracy: 0.8395 - val_loss: 1.0101 - val_accuracy: 0.7890\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5583 - accuracy: 0.8713 - val_loss: 0.9611 - val_accuracy: 0.7980\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.9067 - val_loss: 0.9380 - val_accuracy: 0.8030\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.9236 - val_loss: 0.9392 - val_accuracy: 0.8110\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.2881 - accuracy: 0.9370 - val_loss: 1.0244 - val_accuracy: 0.7940\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.2411 - accuracy: 0.9440 - val_loss: 0.9619 - val_accuracy: 0.8110\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.2120 - accuracy: 0.9476 - val_loss: 1.0461 - val_accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1864 - accuracy: 0.9509 - val_loss: 1.0593 - val_accuracy: 0.8020\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1703 - accuracy: 0.9530 - val_loss: 1.0301 - val_accuracy: 0.8040\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.9543 - val_loss: 1.1085 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1447 - accuracy: 0.9539 - val_loss: 1.1335 - val_accuracy: 0.7980\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1394 - accuracy: 0.9550 - val_loss: 1.1619 - val_accuracy: 0.7960\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1308 - accuracy: 0.9562 - val_loss: 1.1936 - val_accuracy: 0.7910\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9563 - val_loss: 1.2164 - val_accuracy: 0.7870\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1203 - accuracy: 0.9570 - val_loss: 1.1876 - val_accuracy: 0.7950\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1182 - accuracy: 0.9583 - val_loss: 1.2551 - val_accuracy: 0.7870\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1166 - accuracy: 0.9562 - val_loss: 1.2469 - val_accuracy: 0.7950\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6820e34d0>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgjBUiddUQG8"
      },
      "source": [
        "|Description|tra_acc|val_acc|tra_loss|val_loss|\n",
        "|-----------|-------|-------|--------|--------|\n",
        "|64 units   |0.95   |0.79   |0.11   |1.0     |\n",
        "|32 units   |0.96   |0.79   |0.11   |1.24    |\n",
        "|difference |+0.01  |0.00   |0.00   |-0.24   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBbWlg9RPL6P"
      },
      "source": [
        "#### Try using larger layers: 128 units"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cRYJ0pkUDD0",
        "outputId": "fcac0576-8a2c-46cd-c430-67f80013227e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 1.5972 - accuracy: 0.6550 - val_loss: 1.0902 - val_accuracy: 0.7630\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.7679 - accuracy: 0.8321 - val_loss: 0.9763 - val_accuracy: 0.7840\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.4597 - accuracy: 0.9003 - val_loss: 0.8566 - val_accuracy: 0.8190\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.3046 - accuracy: 0.9313 - val_loss: 0.9397 - val_accuracy: 0.8010\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.2289 - accuracy: 0.9444 - val_loss: 0.9165 - val_accuracy: 0.8160\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1909 - accuracy: 0.9515 - val_loss: 0.9224 - val_accuracy: 0.8130\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1665 - accuracy: 0.9540 - val_loss: 0.9963 - val_accuracy: 0.8080\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1563 - accuracy: 0.9530 - val_loss: 0.9957 - val_accuracy: 0.8090\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1329 - accuracy: 0.9562 - val_loss: 1.1003 - val_accuracy: 0.7890\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1332 - accuracy: 0.9554 - val_loss: 1.0846 - val_accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1232 - accuracy: 0.9559 - val_loss: 1.1656 - val_accuracy: 0.7880\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1158 - accuracy: 0.9580 - val_loss: 1.1975 - val_accuracy: 0.7990\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1107 - accuracy: 0.9553 - val_loss: 1.2122 - val_accuracy: 0.7830\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1054 - accuracy: 0.9578 - val_loss: 1.2222 - val_accuracy: 0.8020\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.1027 - accuracy: 0.9575 - val_loss: 1.3445 - val_accuracy: 0.7900\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.0988 - accuracy: 0.9573 - val_loss: 1.3202 - val_accuracy: 0.8060\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0939 - accuracy: 0.9567 - val_loss: 1.5138 - val_accuracy: 0.7840\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.0893 - accuracy: 0.9590 - val_loss: 1.4380 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0882 - accuracy: 0.9583 - val_loss: 1.5327 - val_accuracy: 0.7940\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 0.0835 - accuracy: 0.9583 - val_loss: 1.5867 - val_accuracy: 0.7930\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb6825e1f10>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaFbGTh0UnZl"
      },
      "source": [
        "|Description|tra_acc|val_acc|tra_loss|val_loss|\n",
        "|-----------|-------|-------|--------|--------|\n",
        "|64 units   |0.95   |0.79   |0.11    |1.00    |\n",
        "|128 units  |0.95   |0.79   |0.08    |1.58    |\n",
        "|difference |-0.00  |0.00  |+0.03   |-0.58   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5rb4wOuU-7y"
      },
      "source": [
        "#### try using a single intermediate layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nXSRHCHVHx1",
        "outputId": "e14935a5-82be-4c4d-b37b-0b12b17a9251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 1.8681 - accuracy: 0.6452 - val_loss: 1.2190 - val_accuracy: 0.7350\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.9378 - accuracy: 0.8026 - val_loss: 0.9817 - val_accuracy: 0.7970\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6335 - accuracy: 0.8700 - val_loss: 0.8621 - val_accuracy: 0.8260\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.9088 - val_loss: 0.8221 - val_accuracy: 0.8270\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.3358 - accuracy: 0.9302 - val_loss: 0.8111 - val_accuracy: 0.8330\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.2600 - accuracy: 0.9412 - val_loss: 0.8308 - val_accuracy: 0.8300\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.2132 - accuracy: 0.9454 - val_loss: 0.8349 - val_accuracy: 0.8260\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1846 - accuracy: 0.9520 - val_loss: 0.8602 - val_accuracy: 0.8210\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9530 - val_loss: 0.8893 - val_accuracy: 0.8260\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.9549 - val_loss: 0.8936 - val_accuracy: 0.8260\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.9568 - val_loss: 0.9409 - val_accuracy: 0.8190\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.9562 - val_loss: 0.9555 - val_accuracy: 0.8080\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1224 - accuracy: 0.9559 - val_loss: 1.0134 - val_accuracy: 0.8070\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1200 - accuracy: 0.9578 - val_loss: 1.0192 - val_accuracy: 0.8170\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1133 - accuracy: 0.9579 - val_loss: 1.0500 - val_accuracy: 0.8170\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1117 - accuracy: 0.9583 - val_loss: 1.0602 - val_accuracy: 0.8130\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1070 - accuracy: 0.9609 - val_loss: 1.1080 - val_accuracy: 0.8080\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1098 - accuracy: 0.9541 - val_loss: 1.1095 - val_accuracy: 0.8080\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9578 - val_loss: 1.1442 - val_accuracy: 0.7990\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.9572 - val_loss: 1.1645 - val_accuracy: 0.7980\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb68299fb90>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqTgtEwuWr5p"
      },
      "source": [
        "|Description|tra_acc|val_acc|tra_loss|val_loss|\n",
        "|-----------|-------|-------|--------|--------|\n",
        "|64 units   |0.95   |0.79   |0.11   |1.00     |\n",
        "|128 units  |0.95   |0.79   |0.10    |1.16    |\n",
        "|difference |0.00  |0.00  |+0.01   |-0.16  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byi1xIMRVCwh"
      },
      "source": [
        "#### try using three intermediate layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE-jUOUoVIMv",
        "outputId": "025dc800-640e-4350-b8ce-4700f9e2e074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 1.8925 - accuracy: 0.5926 - val_loss: 1.2847 - val_accuracy: 0.7080\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 1.0028 - accuracy: 0.7781 - val_loss: 1.0739 - val_accuracy: 0.7540\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.6742 - accuracy: 0.8489 - val_loss: 0.9291 - val_accuracy: 0.8060\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.4663 - accuracy: 0.8996 - val_loss: 0.9887 - val_accuracy: 0.7930\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.9268 - val_loss: 0.9836 - val_accuracy: 0.8070\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.2636 - accuracy: 0.9385 - val_loss: 1.0821 - val_accuracy: 0.7850\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.2103 - accuracy: 0.9491 - val_loss: 1.0888 - val_accuracy: 0.7990\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1885 - accuracy: 0.9510 - val_loss: 1.0712 - val_accuracy: 0.8060\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1702 - accuracy: 0.9516 - val_loss: 1.0711 - val_accuracy: 0.8040\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1545 - accuracy: 0.9551 - val_loss: 1.1593 - val_accuracy: 0.7900\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1451 - accuracy: 0.9559 - val_loss: 1.1601 - val_accuracy: 0.7950\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1377 - accuracy: 0.9536 - val_loss: 1.3061 - val_accuracy: 0.7800\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1322 - accuracy: 0.9544 - val_loss: 1.3592 - val_accuracy: 0.7680\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1238 - accuracy: 0.9577 - val_loss: 1.2118 - val_accuracy: 0.7980\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1197 - accuracy: 0.9562 - val_loss: 1.4191 - val_accuracy: 0.7810\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 0.9568 - val_loss: 1.2964 - val_accuracy: 0.7960\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1146 - accuracy: 0.9565 - val_loss: 1.4252 - val_accuracy: 0.7870\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1069 - accuracy: 0.9562 - val_loss: 1.4085 - val_accuracy: 0.7850\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.1046 - accuracy: 0.9559 - val_loss: 1.5034 - val_accuracy: 0.7920\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.1017 - accuracy: 0.9568 - val_loss: 1.4650 - val_accuracy: 0.7880\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb682652050>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    partial_x_train,\n",
        "    partial_y_train,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mv2idd1Ws0B"
      },
      "source": [
        "|Description|tra_acc|val_acc|tra_loss|val_loss|\n",
        "|-----------|-------|-------|--------|--------|\n",
        "|64 units   |0.95   |0.79   |0.11   |1.0     |\n",
        "|128 units   |0.95  |0.78  |0.10    |1.46    |\n",
        "|difference |0.00  |+0.01  |+0.01   |-0.46   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QapVUYH1V5e_"
      },
      "source": [
        "### 4.2.9 Wrapping up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoBLIYvvV_Mp"
      },
      "source": [
        "- If you’re trying to classify data points among N classes, your model should end with a Dense layer of size N.\n",
        "- In a single-label, multiclass classification problem your model should end with a softmax activation so that it will output a probability distribution over the N output classes.\n",
        "- Categorical crossentropy is almost always the loss function you should use for such problems. It minimizes the distance between the probability distributions output by the model and the true distribution of the targets.\n",
        "- There are two ways to handle labels in multiclass classification:\n",
        "  - Encoding the labels via categorical encoding (also known as one-hot encoding) and using categorical_crossentropy as a loss function\n",
        "  - Encoding the labels as integers and using the sparse_categorical_crossentropy loss function\n",
        "- If you need to classify data into a large number of categories, you should avoid creating information bottlenecks in your model due to intermediate layers that are too small."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "4.2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
