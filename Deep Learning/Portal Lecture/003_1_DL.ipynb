{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Anatomy of Neural Networks\n",
    "- a neural network revolves around the following objects:\n",
    "    - Layers, which are combined into a network (or model)\n",
    "    - The input data and corresponding targets\n",
    "    - The loss function, which defines the feedback signal used for learning\n",
    "    - The optimizer, which determines how learning proceeds\n",
    "\n",
    "- Network, layers, loss function and optimizer relation\n",
    "\n",
    "    ![](./snaps/3-1.PNG)\n",
    "\n",
    "- Layers: the building blocks of deep learning\n",
    "    - The fundamental data structure in neural networks is the layer. A layer takes as input one or more tensors and that outputs one or more tensors. Usually layers store the state or knowledge in form of weights. There are different types of layers available for different tasks, like:\n",
    "        - Dense layers or fully connected layers are used for 2D tensors of shape (samples,features)\n",
    "        - Recurrent layers are used for sequence or 3D tensors of shape (samples,timesteps,features)\n",
    "        - 2D concolution layers are used for images stored in 4D tensors\n",
    "    - The notion of layer compatibility here refers specifically to the fact that every layer will only accept input tensors of a certain shape and will return output tensors of a certain shape. Consider the following example:\n",
    "        - `layer = layers.Dense(32, input_shape=(784,))`\n",
    "        - This layer accepts 784 features (axis 0) and unspecified / any number of samples (axis 1). The output of the layer is 32 at axis 1.\n",
    "    - In keras, layer object has built in feature to adopt to the shape of its input data. So the developer doesn't have to wory about it.\n",
    "        ```\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(32, input_shape=(784,)))\n",
    "        model.add(layers.Dense(32))\n",
    "        ```\n",
    "- Models: networks of layers\n",
    "    - A deep-learning model is a directed, acyclic graph of layers. The most common instance is a linear stack of layers, mapping a single input to a single output.\n",
    "    - But as you move forward, you’ll be exposed to a much broader variety of network topologies. Some common ones include the following:\n",
    "        - Two-branch networks\n",
    "        - Multihead networks\n",
    "        - Inception blocks\n",
    "    - Picking the right network architecture is more an art than a science; and although there are some best practices and principles you can rely on, only practice can help you become a proper neural-network architect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Loss Function and Optimizers\n",
    "- Once the network architecture is defined, you still have to choose two more things:\n",
    "    - Loss function (objective function)—The quantity that will be minimized during training. It represents a measure of success for the task at hand.\n",
    "    - Optimizer—Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\n",
    "- Choosing the right objective function for the right problem is extremely important: your network will take any shortcut it can, to minimize the loss; so if the objective doesn’t fully correlate with success for the task at hand, your network will end up doing things you may not have wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Intorduction to Keras\n",
    "- Keras is a deep-learning framework for Python that provides a convenient way to define and train almost any kind of deep-learning model. Keras was initially developed for researchers, with the aim of enabling fast experimentation. Keras has the following key features:\n",
    "    - It allows the same code to run seamlessly on CPU or GPU.\n",
    "    - It has a user-friendly API that makes it easy to quickly prototype deep-learning models.\n",
    "    - It has built-in support for convolutional networks (for computer vision), recurrent networks (for sequence processing), and any combination of both.\n",
    "    - It supports arbitrary network architectures: multi-input or multi-output models, layer sharing, model sharing, and so on. This means Keras is appropriate for building essentially any deep-learning model, from a generative adversarial network to a neural Turing machine\n",
    "\n",
    "    ![](./snaps/3-2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Quick Review of Keras\n",
    "- You’ve already seen one example of a Keras model: the MNIST example. The typical Keras workflow looks just like that example:\n",
    "    1. Define your training data: input tensors and target tensors.\n",
    "    2. Define a network of layers (or model ) that maps your inputs to your targets.\n",
    "    3. Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n",
    "    4. Iterate on your training data by calling the fit() method of your model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
